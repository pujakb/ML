{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing softwares libraries and Loading the dataset (Liar Liar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filename = 'test.csv'\n",
    "train_filename = 'train.csv'\n",
    "valid_filename = 'valid.csv'\n",
    "\n",
    "train_news = pd.read_csv (r'C:\\PUJAMS\\machinelearning\\csvfiles\\liar_dataset\\train.csv')\n",
    "test_news = pd.read_csv (r'C:\\PUJAMS\\machinelearning\\csvfiles\\liar_dataset\\test.csv')\n",
    "valid_news = pd.read_csv (r'C:\\PUJAMS\\machinelearning\\csvfiles\\liar_dataset\\valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset size:\n",
      "(10240, 2)\n",
      "                                           Statement  Label\n",
      "0  Says the Annies List political group supports ...  False\n",
      "1  When did the decline of coal start? It started...   True\n",
      "2  Hillary Clinton agrees with John McCain \"by vo...   True\n",
      "3  Health care reform legislation is likely to ma...  False\n",
      "4  The economic turnaround started at the end of ...   True\n",
      "5  The Chicago Bears have had more starting quart...   True\n",
      "6  Jim Dunnam has not lived in the district he re...  False\n",
      "7  I'm the only person on this stage who has work...   True\n",
      "8  However, it took $19.5 million in Oregon Lotte...   True\n",
      "9  Says GOP primary opponents Glenn Grothman and ...   True\n",
      "(2551, 2)\n",
      "                                           Statement  Label\n",
      "0  Building a wall on the U.S.-Mexico border will...   True\n",
      "1  Wisconsin is on pace to double the number of l...  False\n",
      "2  Says John McCain has done nothing to help the ...  False\n",
      "3  Suzanne Bonamici supports a plan that will cut...   True\n",
      "4  When asked by a reporter whether hes at the ce...  False\n",
      "5  Over the past five years the federal governmen...   True\n",
      "6  Says that Tennessee law requires that schools ...   True\n",
      "7  Says Vice President Joe Biden \"admits that the...  False\n",
      "8  Donald Trump is against marriage equality. He ...   True\n",
      "9  We know that more than half of Hillary Clinton...  False\n",
      "(2571, 2)\n",
      "                                           Statement  Label\n",
      "0  We have less Americans working now than in the...  FALSE\n",
      "1  When Obama was sworn into office, he DID NOT u...  FALSE\n",
      "2  Says Having organizations parading as being so...  FALSE\n",
      "3     Says nearly half of Oregons children are poor.   TRUE\n",
      "4  On attacks by Republicans that various program...   TRUE\n",
      "5  Says when armed civilians stop mass shootings ...  FALSE\n",
      "6  Says Tennessee is providing millions of dollar...   TRUE\n",
      "7  The health care reform plan would set limits s...  FALSE\n",
      "8  Says Donald Trump started his career back in 1...   TRUE\n",
      "9  Bill White has a long history of trying to lim...   TRUE\n",
      "Checking data qualitites...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10240 entries, 0 to 10239\n",
      "Data columns (total 2 columns):\n",
      "Statement    10240 non-null object\n",
      "Label        10240 non-null bool\n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 90.1+ KB\n",
      "check finished.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2551 entries, 0 to 2550\n",
      "Data columns (total 2 columns):\n",
      "Statement    2551 non-null object\n",
      "Label        2551 non-null bool\n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 22.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2571 entries, 0 to 2570\n",
      "Data columns (total 2 columns):\n",
      "Statement    2571 non-null object\n",
      "Label        2569 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 40.2+ KB\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def data_obs():\n",
    "    print(\"training dataset size:\")\n",
    "    print(train_news.shape)\n",
    "    print(train_news.head(10))\n",
    "\n",
    "    #below dataset were used for testing and validation purposes\n",
    "    print(test_news.shape)\n",
    "    print(test_news.head(10))\n",
    "    \n",
    "    print(valid_news.shape)\n",
    "    print(valid_news.head(10))\n",
    "    \n",
    "data_obs()\n",
    "    \n",
    "def create_distribution(dataFile):\n",
    "    return sb.countplot(x='Label', data=dataFile, palette='hls')\n",
    "\n",
    "create_distribution(train_news)\n",
    "create_distribution(test_news)\n",
    "create_distribution(valid_news)\n",
    "\n",
    "def data_qualityCheck():\n",
    "    \n",
    "    print(\"Checking data qualitites...\")\n",
    "    train_news.isnull().sum()\n",
    "    train_news.info()\n",
    "        \n",
    "    print(\"check finished.\")\n",
    "\n",
    "    #below datasets were used to \n",
    "    test_news.isnull().sum()\n",
    "    test_news.info()\n",
    "\n",
    "    valid_news.isnull().sum()\n",
    "    valid_news.info()\n",
    "    \n",
    "#uality check - \n",
    "    \n",
    "data_qualityCheck()\n",
    "eng_stemmer = SnowballStemmer('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "#Stemming\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for token in tokens:\n",
    "        stemmed.append(stemmer.stem(token))\n",
    "    return stemmed\n",
    "\n",
    "#process the data\n",
    "def process_data(data,exclude_stopword=True,stem=True):\n",
    "    tokens = [w.lower() for w in data]\n",
    "    tokens_stemmed = tokens\n",
    "    tokens_stemmed = stem_tokens(tokens, eng_stemmer)\n",
    "    tokens_stemmed = [w for w in tokens_stemmed if w not in stopwords ]\n",
    "    return tokens_stemmed\n",
    "\n",
    "\n",
    "#creating ngrams\n",
    "#unigram \n",
    "def create_unigram(words):\n",
    "    assert type(words) == list\n",
    "    return words\n",
    "\n",
    "#bigram\n",
    "def create_bigrams(words):\n",
    "    assert type(words) == list\n",
    "    skip = 0\n",
    "    join_str = \" \"\n",
    "    Len = len(words)\n",
    "    if Len > 1:\n",
    "        lst = []\n",
    "        for i in range(Len-1):\n",
    "            for k in range(1,skip+2):\n",
    "                if i+k < Len:\n",
    "                    lst.append(join_str.join([words[i],words[i+k]]))\n",
    "    else:\n",
    "        #set it as unigram\n",
    "        lst = create_unigram(words)\n",
    "    return lst\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#converting multiclass labels present in our datasets to binary class labels\\nfor i , row in data_TrainNews.iterrows():\\n    if (data_TrainNews.iloc[:,0] == \"mostly-true\" | data_TrainNews.iloc[:,0] == \"half-true\" | data_TrainNews.iloc[:,0] == \"true\"):\\n        data_TrainNews.iloc[:,0] = \"true\"\\n    else :\\n        data_TrainNews.iloc[:,0] = \"false\"\\n        \\nfor i,row in data_TrainNews.iterrows():\\n    print(row)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the distribution of labels in the train and test data\n",
    "\"\"\"def create_datafile(filename)\n",
    "    #function to slice the dataframe to keep variables necessary to be used for classification\n",
    "    return \"return df to be used\"\n",
    "\"\"\"\n",
    "    \n",
    "\"\"\"#converting multiclass labels present in our datasets to binary class labels\n",
    "for i , row in data_TrainNews.iterrows():\n",
    "    if (data_TrainNews.iloc[:,0] == \"mostly-true\" | data_TrainNews.iloc[:,0] == \"half-true\" | data_TrainNews.iloc[:,0] == \"true\"):\n",
    "        data_TrainNews.iloc[:,0] = \"true\"\n",
    "    else :\n",
    "        data_TrainNews.iloc[:,0] = \"false\"\n",
    "        \n",
    "for i,row in data_TrainNews.iterrows():\n",
    "    print(row)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "import nltk\n",
    "nltk.download()\n",
    "import nltk.corpus \n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "  (0, 3278)\t1\n",
      "  (0, 7728)\t1\n",
      "  (0, 615)\t1\n",
      "  (0, 11296)\t1\n",
      "  (0, 11036)\t1\n",
      "  (0, 10709)\t1\n",
      "  (0, 5115)\t1\n",
      "  (0, 8376)\t1\n",
      "  (0, 6639)\t1\n",
      "  (0, 1044)\t1\n",
      "  (0, 10988)\t1\n",
      "  (0, 9676)\t1\n",
      "  (1, 751)\t1\n",
      "  (1, 1964)\t1\n",
      "  (1, 4910)\t1\n",
      "  (1, 8554)\t1\n",
      "  (1, 5687)\t1\n",
      "  (1, 1532)\t1\n",
      "  (1, 11110)\t1\n",
      "  (1, 10980)\t1\n",
      "  (1, 7674)\t1\n",
      "  (1, 11138)\t1\n",
      "  (1, 4860)\t1\n",
      "  (1, 7418)\t1\n",
      "  (1, 10426)\t2\n",
      "  :\t:\n",
      "  (10239, 6853)\t1\n",
      "  (10239, 10594)\t1\n",
      "  (10239, 3989)\t1\n",
      "  (10239, 10918)\t1\n",
      "  (10239, 8996)\t1\n",
      "  (10239, 10660)\t1\n",
      "  (10239, 2549)\t1\n",
      "  (10239, 11622)\t1\n",
      "  (10239, 2568)\t1\n",
      "  (10239, 799)\t1\n",
      "  (10239, 11660)\t2\n",
      "  (10239, 12158)\t1\n",
      "  (10239, 3309)\t1\n",
      "  (10239, 11004)\t1\n",
      "  (10239, 11013)\t1\n",
      "  (10239, 6603)\t1\n",
      "  (10239, 6327)\t1\n",
      "  (10239, 12151)\t2\n",
      "  (10239, 1159)\t1\n",
      "  (10239, 7824)\t1\n",
      "  (10239, 7828)\t1\n",
      "  (10239, 5267)\t1\n",
      "  (10239, 11110)\t2\n",
      "  (10239, 7672)\t2\n",
      "  (10239, 10988)\t1\n"
     ]
    }
   ],
   "source": [
    "countV = CountVectorizer()\n",
    "train_count = countV.fit_transform(train_news['Statement'].values)\n",
    "\n",
    "print(countV)\n",
    "print(train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_countVectorizer_stats():\n",
    "    \n",
    "    #vocab size\n",
    "    train_count.shape\n",
    "\n",
    "    #check vocabulary using below command\n",
    "    print(countV.vocabulary_)\n",
    "\n",
    "    #get feature names\n",
    "    print(countV.get_feature_names()[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf \n",
    "tfidfV = TfidfTransformer()\n",
    "train_tfidf = tfidfV.fit_transform(train_count)\n",
    "\n",
    "def get_tfidf_stats():\n",
    "    train_tfidf.shape\n",
    "    #get train data feature names \n",
    "    print(train_tfidf.A[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_ngram = TfidfVectorizer(stop_words='english',ngram_range=(1,4),use_idf=True,smooth_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words - with n-grams\n",
    "countV_ngram = CountVectorizer(ngram_range=(1,3),stop_words='english')\n",
    "tfidf_ngram  = TfidfTransformer(use_idf=True,smooth_idf=True)\n",
    "tfidf_ngram = TfidfVectorizer(stop_words='english',ngram_range=(1,4),use_idf=True,smooth_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untag(tagged_sentence):\n",
    "    return [w for w, t in tagged_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Says the Annies List political group supports ...\n",
      "1        When did the decline of coal start? It started...\n",
      "2        Hillary Clinton agrees with John McCain \"by vo...\n",
      "3        Health care reform legislation is likely to ma...\n",
      "4        The economic turnaround started at the end of ...\n",
      "5        The Chicago Bears have had more starting quart...\n",
      "6        Jim Dunnam has not lived in the district he re...\n",
      "7        I'm the only person on this stage who has work...\n",
      "8        However, it took $19.5 million in Oregon Lotte...\n",
      "9        Says GOP primary opponents Glenn Grothman and ...\n",
      "10       For the first time in history, the share of th...\n",
      "11       Since 2000, nearly 12 million Americans have s...\n",
      "12       When Mitt Romney was governor of Massachusetts...\n",
      "13       The economy bled $24 billion due to the govern...\n",
      "14       Most of the (Affordable Care Act) has already ...\n",
      "15       In this last election in November, ... 63 perc...\n",
      "16       McCain opposed a requirement that the governme...\n",
      "17       U.S. Rep. Ron Kind, D-Wis., and his fellow Dem...\n",
      "18       Water rates in Manila, Philippines, were raise...\n",
      "19       Almost 100,000 people left Puerto Rico last year.\n",
      "20       Women and men both are making less when you ad...\n",
      "21       The United States has the highest corporate ta...\n",
      "22       We just had the best year for the auto industr...\n",
      "23       Says Scott Walker favors cutting up to 350,000...\n",
      "24       Says Mitt Romney wants to get rid of Planned P...\n",
      "25                   I dont know who (Jonathan Gruber) is.\n",
      "26       Hate crimes against American Muslims and mosqu...\n",
      "27       Rick Perry has never lost an election and rema...\n",
      "28       ISIS supporter tweeted at 10:34 a.m. Shooting ...\n",
      "29       Youth unemployment in minority communities is ...\n",
      "                               ...                        \n",
      "10210    Since the Affordable Care Act passed, 90 perce...\n",
      "10211    Debt has almost doubled in Austin under Gov. P...\n",
      "10212    Lets say (Republicans) take away half of our d...\n",
      "10213    Theres a tremendous other number of public off...\n",
      "10214    Under last years health care reform, a bunch o...\n",
      "10215    The Obama administration spent $205,075 in sti...\n",
      "10216    There has been no net global warming for over ...\n",
      "10217    Thanks to the Obama administrations negotiatio...\n",
      "10218    This race will be the Democrats top target thi...\n",
      "10219    Georgia Public Service Commission member Stan ...\n",
      "10220    Says he and Mitt Romney agreed on tying minimu...\n",
      "10221    As a result of Obamacare, California seniors f...\n",
      "10222    For the first time since the Korean War, total...\n",
      "10223    Says Rick Perry turned down our invitation to ...\n",
      "10224    In 2012, the state put together a list of over...\n",
      "10225    The Republican Party lost 1.1 million register...\n",
      "10226    The proudest accomplishment (of my tenure) was...\n",
      "10227    Recently though, the media has reported on tho...\n",
      "10228    Stopped by Smiley Cookie to pick up some great...\n",
      "10229     Mike Trainor...still owes $250,000 to the state.\n",
      "10230    The Supreme Courts views are radically out of ...\n",
      "10231    When it comes to the state deficit, Wisconsin ...\n",
      "10232    Eighty percent of the net new jobs created in ...\n",
      "10233    Mayor Fung wants to punish our childrens educa...\n",
      "10234    Under the ruling of the Supreme Court, any lob...\n",
      "10235    There are a larger number of shark attacks in ...\n",
      "10236    Democrats have now become the party of the [At...\n",
      "10237    Says an alternative to Social Security that op...\n",
      "10238    On lifting the U.S. Cuban embargo and allowing...\n",
      "10239    The Department of Veterans Affairs has a manua...\n",
      "Name: Statement, Length: 10240, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#POS Tagging\n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    "\n",
    "cutoff = int(.75 * len(tagged_sentences))\n",
    "training_sentences = train_news['Statement']\n",
    "print(training_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Word2Vec \n",
    "import numpy as np\n",
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print (\"Done.\"),len(model),\" words loaded!\"\n",
    "    return model\n",
    "\n",
    "# with open(\"glove.6B.50d.txt\", \"rb\") as lines:\n",
    "    w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "           for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass TfidfEmbeddingVectorizer(object):\\n    def __init__(self, word2vec):\\n        self.word2vec = word2vec\\n        self.word2weight = None\\n        self.dim = len(word2vec.itervalues().next())\\n\\n    def fit(self, X, y):\\n        tfidf = TfidfVectorizer(analyzer=lambda x: x)\\n        tfidf.fit(X)\\n        # if a word was never seen - it must be at least as infrequent\\n        # as any of the known words - so the default idf is the max of \\n        # known idf's\\n        max_idf = max(tfidf.idf_)\\n        self.word2weight = defaultdict(\\n            lambda: max_idf,\\n            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\\n\\n        return self\\n\\n    def transform(self, X):\\n        return np.array([\\n                np.mean([self.word2vec[w] * self.word2weight[w]\\n                         for w in words if w in self.word2vec] or\\n                        [np.zeros(self.dim)], axis=0)\\n                for words in X\\n            ])\\n\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string to test\n",
    "doc_new = ['obama is running for president in 2016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.66961153965076\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2118 2370]\n",
      " [1664 4088]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.6467929151165771\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2252 2236]\n",
      " [1934 3818]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.6104687487924283\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2260 2228]\n",
      " [2246 3506]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.6489265899683886\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2262 2226]\n",
      " [1919 3833]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e9439a31d84d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[0mbuild_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_pipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[0mbuild_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgd_pipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mbuild_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_forest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-e9439a31d84d>\u001b[0m in \u001b[0;36mbuild_confusion_matrix\u001b[1;34m(classifier)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_news\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Using bag of words\n",
    "#building classifier using naive bayes \n",
    "nb_pipeline = Pipeline([\n",
    "        ('NBCV',countV),\n",
    "        ('nb_clf',MultinomialNB())])\n",
    "\n",
    "nb_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_nb = nb_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_nb == test_news['Label'])\n",
    "\n",
    "\n",
    "#building classifier using logistic regression\n",
    "logR_pipeline = Pipeline([\n",
    "        ('LogRCV',countV),\n",
    "        ('LogR_clf',LogisticRegression())\n",
    "        ])\n",
    "\n",
    "logR_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_LogR = logR_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_LogR == test_news['Label'])\n",
    "\n",
    "\n",
    "#building Linear SVM classfier\n",
    "svm_pipeline = Pipeline([\n",
    "        ('svmCV',countV),\n",
    "        ('svm_clf',svm.LinearSVC())\n",
    "        ])\n",
    "\n",
    "svm_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_svm = svm_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_svm == test_news['Label'])\n",
    "\n",
    "\n",
    "#using SVM Stochastic Gradient Descent on hinge loss\n",
    "sgd_pipeline = Pipeline([\n",
    "        ('svm2CV',countV),\n",
    "        ('svm2_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5))\n",
    "        ])\n",
    "\n",
    "sgd_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_sgd = sgd_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_sgd == test_news['Label'])\n",
    "\n",
    "\n",
    "#random forest\n",
    "random_forest = Pipeline([\n",
    "        ('rfCV',countV),\n",
    "        ('rf_clf',RandomForestClassifier(n_estimators=200,n_jobs=3))\n",
    "        ])\n",
    "    \n",
    "random_forest.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_rf = random_forest.predict(test_news['Statement'])\n",
    "np.mean(predicted_rf == test_news['Label'])\n",
    "\n",
    "\n",
    "#User defined functon for K-Fold cross validatoin\n",
    "def build_confusion_matrix(classifier):\n",
    "    \n",
    "    k_fold = KFold(n=len(train_news), n_folds=5)\n",
    "    scores = []\n",
    "    confusion = np.array([[0,0],[0,0]])\n",
    "\n",
    "    for train_ind, test_ind in k_fold:\n",
    "        train_text = train_news.iloc[train_ind]['Statement'] \n",
    "        train_y = train_news.iloc[train_ind]['Label']\n",
    "    \n",
    "        test_text = train_news.iloc[test_ind]['Statement']\n",
    "        test_y = train_news.iloc[test_ind]['Label']\n",
    "        \n",
    "        classifier.fit(train_text,train_y)\n",
    "        predictions = classifier.predict(test_text)\n",
    "        \n",
    "        confusion += confusion_matrix(test_y,predictions)\n",
    "        score = f1_score(test_y,predictions)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return (print('Total statements classified:', len(train_news)),\n",
    "    print('Score:', sum(scores)/len(scores)),\n",
    "    print('score length', len(scores)),\n",
    "    print('Confusion matrix:'),\n",
    "    print(confusion))\n",
    "    \n",
    "#K-fold cross validation for all classifiers\n",
    "build_confusion_matrix(nb_pipeline)\n",
    "build_confusion_matrix(logR_pipeline)\n",
    "build_confusion_matrix(svm_pipeline)\n",
    "build_confusion_matrix(sgd_pipeline)\n",
    "build_confusion_matrix(random_forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words confusion matrix and F1 scores\n",
    "\n",
    "Naive bayes\n",
    "[2118 2370]\n",
    "[1664 4088]\n",
    "f1-Score: 0.669611539651\n",
    "\n",
    "Logistic regression\n",
    "[2252 2236]\n",
    "[1933 3819]\n",
    "f1-Score: 0.646909097798\n",
    "\n",
    "svm\n",
    "[2260 2228]\n",
    "[2246 3506]\n",
    "f1-score: 0.610468748792\n",
    "\n",
    "sgdclassifier\n",
    "[2414 2074]\n",
    "[2042 3710]\n",
    "f1-Score: 0.640874558778\n",
    "\n",
    "random forest classifier\n",
    "[1821 2667]\n",
    "[1192 4560]\n",
    "f1-Score: 0.702651511011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.7224053159841455\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[ 758 3730]\n",
      " [ 390 5362]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.7044355553757985\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1580 2908]\n",
      " [1043 4709]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.6790920142902143\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2016 2472]\n",
      " [1524 4228]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.7190643331130575\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[   5 4483]\n",
      " [   6 5746]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4a345430e4f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mbuild_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_pipeline_ngram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[0mbuild_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgd_pipeline_ngram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mbuild_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_forest_ngram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-e9439a31d84d>\u001b[0m in \u001b[0;36mbuild_confusion_matrix\u001b[1;34m(classifier)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_news\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##Now using n-grams\n",
    "#naive-bayes classifier\n",
    "nb_pipeline_ngram = Pipeline([\n",
    "        ('nb_tfidf',tfidf_ngram),\n",
    "        ('nb_clf',MultinomialNB())])\n",
    "\n",
    "nb_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_nb_ngram = nb_pipeline_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_nb_ngram == test_news['Label'])\n",
    "\n",
    "\n",
    "#logistic regression classifier\n",
    "logR_pipeline_ngram = Pipeline([\n",
    "        ('LogR_tfidf',tfidf_ngram),\n",
    "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
    "        ])\n",
    "\n",
    "logR_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_LogR_ngram = logR_pipeline_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_LogR_ngram == test_news['Label'])\n",
    "\n",
    "\n",
    "#linear SVM classifier\n",
    "svm_pipeline_ngram = Pipeline([\n",
    "        ('svm_tfidf',tfidf_ngram),\n",
    "        ('svm_clf',svm.LinearSVC())\n",
    "        ])\n",
    "\n",
    "svm_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_svm_ngram = svm_pipeline_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_svm_ngram == test_news['Label'])\n",
    "\n",
    "\n",
    "#sgd classifier\n",
    "sgd_pipeline_ngram = Pipeline([\n",
    "         ('sgd_tfidf',tfidf_ngram),\n",
    "         ('sgd_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5))\n",
    "         ])\n",
    "\n",
    "sgd_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_sgd_ngram = sgd_pipeline_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_sgd_ngram == test_news['Label'])\n",
    "\n",
    "\n",
    "#random forest classifier\n",
    "random_forest_ngram = Pipeline([\n",
    "        ('rf_tfidf',tfidf_ngram),\n",
    "        ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3))\n",
    "        ])\n",
    "    \n",
    "random_forest_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_rf_ngram = random_forest_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_rf_ngram == test_news['Label'])\n",
    "\n",
    "\n",
    "#K-fold cross validation for all classifiers\n",
    "build_confusion_matrix(nb_pipeline_ngram)\n",
    "build_confusion_matrix(logR_pipeline_ngram)\n",
    "build_confusion_matrix(svm_pipeline_ngram)\n",
    "build_confusion_matrix(sgd_pipeline_ngram)\n",
    "build_confusion_matrix(random_forest_ngram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n-grams & tfidf confusion matrix and F1 scores\n",
    "\n",
    "Naive bayes\n",
    "[841 3647]\n",
    "[427 5325]\n",
    "f1-Score: 0.723262051071\n",
    "\n",
    "Logistic regression\n",
    "[1617 2871]\n",
    "[1097 4655]\n",
    "f1-Score: 0.70113000531\n",
    "\n",
    "svm\n",
    "[2016 2472]\n",
    "[1524 4228]\n",
    "f1-Score: 0.67909201429\n",
    "\n",
    "sgdclassifier\n",
    "[  10 4478]\n",
    "[  13 5739]\n",
    "f1-Score: 0.718731637053\n",
    "\n",
    "random forest\n",
    "[1979 2509]\n",
    "[1630 4122]\n",
    "f1-Score: 0.665720333284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.72      0.19      0.30      1169\n",
      "       True       0.58      0.94      0.71      1382\n",
      "\n",
      "avg / total       0.64      0.59      0.52      2551\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.64      0.39      0.49      1169\n",
      "       True       0.61      0.81      0.70      1382\n",
      "\n",
      "avg / total       0.62      0.62      0.60      2551\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.61      0.47      0.53      1169\n",
      "       True       0.62      0.74      0.68      1382\n",
      "\n",
      "avg / total       0.62      0.62      0.61      2551\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.00      0.00      0.00      1169\n",
      "       True       0.54      1.00      0.70      1382\n",
      "\n",
      "avg / total       0.29      0.54      0.38      2551\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.58      0.48      0.53      1169\n",
      "       True       0.62      0.70      0.66      1382\n",
      "\n",
      "avg / total       0.60      0.60      0.60      2551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_news['Label'], predicted_nb_ngram))\n",
    "print(classification_report(test_news['Label'], predicted_LogR_ngram))\n",
    "print(classification_report(test_news['Label'], predicted_svm_ngram))\n",
    "print(classification_report(test_news['Label'], predicted_sgd_ngram))\n",
    "print(classification_report(test_news['Label'], predicted_rf_ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_news['Label'].shape\n",
    "\n",
    "\"\"\"\n",
    "Out of all the models fitted, we would take 2 best performing model. we would call them candidate models\n",
    "from the confusion matrix, we can see that random forest and logistic regression are best performing \n",
    "in terms of precision and recall (take a look into false positive and true negative counts which appeares\n",
    "to be low compared to rest of the models)\n",
    "\"\"\"\n",
    "\n",
    "#grid-search parameter optimization\n",
    "#random forest classifier parameters\n",
    "parameters = {'rf_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'rf_tfidf__use_idf': (True, False),\n",
    "               'rf_clf__max_depth': (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 1.03430629,  1.33770633,  1.8493367 ,  1.74957053,  2.76480722,\n",
       "         2.63380551,  3.35320624,  3.70700661,  4.1704073 ,  4.16000732,\n",
       "         1.49240255,  1.61200285,  2.15800365,  2.06960352,  2.97303923,\n",
       "         2.91397262,  3.62960625,  3.97800692,  4.64527464,  4.69938207,\n",
       "         1.78910931,  1.8422699 ,  2.16737048,  2.19983745,  3.25000572,\n",
       "         3.20320559,  3.78643982,  4.08804043,  4.94520871,  4.67900864,\n",
       "         1.72350311,  1.87200324,  2.38160412,  2.41800427,  3.11480538,\n",
       "         3.15723904,  4.46160777,  4.5828747 ,  4.95460908,  4.86720848,\n",
       "         2.1320037 ,  1.86763676,  2.41363764,  2.49080435,  3.4788061 ,\n",
       "         3.58407315,  4.29504116,  4.37320773,  5.23934269,  5.2378761 ,\n",
       "         2.10080361,  1.97080334,  2.69840511,  2.73793848,  3.5618062 ,\n",
       "         3.65040644,  4.76260861,  4.70600843,  5.58044314,  5.56221048,\n",
       "         2.12743719,  2.0176034 ,  2.73500482,  2.9898053 ,  4.24320745,\n",
       "         4.22240726,  5.07107576,  5.20821166,  6.28291504,  5.32044268,\n",
       "         2.26200398,  2.07480375,  3.46820609,  2.82383855,  4.38674108,\n",
       "         4.44414107,  4.93814206,  5.61046314,  6.96330237,  6.66284307,\n",
       "         2.49803535,  2.70920833,  4.11785332,  3.95884196,  5.41784684,\n",
       "         4.54143937,  6.64729079,  5.49249593,  6.37910231,  6.37465525,\n",
       "         2.71347356,  2.65229845,  4.12626886,  3.69875097,  5.20009057,\n",
       "         4.79264625,  6.22325548,  6.29052655,  6.90799538,  6.85973191,\n",
       "         2.66344515,  2.48541164,  4.16951911,  4.81245017,  6.42729084,\n",
       "         6.50251865,  8.05679027,  7.35161138,  8.19263061,  7.55312824,\n",
       "         2.79894265,  2.44807545,  4.5496877 ,  4.71582166,  7.1666433 ,\n",
       "         7.00940037,  7.46242627,  7.27831443,  7.78949102,  8.36872363,\n",
       "         3.83269151,  3.24754993,  5.90842398,  5.63771741,  6.83090281,\n",
       "         6.41092642,  7.01956654,  7.34887083,  9.89917898,  9.58440415,\n",
       "         3.47195872,  2.8057456 ,  5.39879131,  5.34919771,  6.42881958,\n",
       "         6.52469333,  8.03830465,  7.97300839,  8.43203171,  9.38108357,\n",
       "         3.83890899,  3.60254288,  6.49671165,  5.94367766,  8.31397589,\n",
       "         7.03118388,  9.44405333,  8.73697782, 11.78032955, 10.91595634]),\n",
       " 'std_fit_time': array([0.1369706 , 0.02753588, 0.0978165 , 0.12306253, 0.31853418,\n",
       "        0.21264535, 0.2700513 , 0.20252012, 0.30790023, 0.33995498,\n",
       "        0.25738729, 0.1288512 , 0.05743595, 0.28060796, 0.19135394,\n",
       "        0.34066994, 0.27209524, 0.18763309, 0.19721311, 0.05425666,\n",
       "        0.31324806, 0.21308856, 0.04868433, 0.23063234, 0.08946428,\n",
       "        0.07015197, 0.11482964, 0.43409145, 0.34461578, 0.28410448,\n",
       "        0.16238015, 0.15651938, 0.16961917, 0.21765618, 0.07782669,\n",
       "        0.23182371, 0.30569673, 0.2571448 , 0.20078364, 0.25089711,\n",
       "        0.08480959, 0.25367477, 0.16987858, 0.28491124, 0.58467156,\n",
       "        0.40763381, 0.03315672, 0.30204838, 0.28972805, 0.62804694,\n",
       "        0.34185856, 0.40406454, 0.03903452, 0.198776  , 0.01918971,\n",
       "        0.04592516, 0.89907539, 0.49484848, 0.42333821, 0.32001152,\n",
       "        0.0372255 , 0.08946428, 0.15543947, 0.3578022 , 0.21045591,\n",
       "        0.51932454, 0.45822238, 0.59431891, 0.45057375, 0.28590834,\n",
       "        0.65890504, 0.11321217, 0.40387407, 0.02777107, 0.09789439,\n",
       "        0.43878042, 0.41383512, 0.52593463, 0.37888577, 0.85245372,\n",
       "        0.29418471, 0.07286892, 0.34204954, 0.51566398, 1.26147548,\n",
       "        0.46141565, 0.58531721, 0.55435668, 0.42392335, 0.29247954,\n",
       "        0.33606934, 0.50608285, 0.25283049, 0.33490805, 0.21168387,\n",
       "        0.24002953, 0.72571967, 0.19232129, 0.65827395, 0.30226796,\n",
       "        0.18588862, 0.55764553, 0.29115512, 0.72873559, 1.10000198,\n",
       "        0.48289267, 1.04313317, 0.34870579, 1.00858177, 1.53138507,\n",
       "        0.16088147, 0.39840669, 0.57081518, 0.4102409 , 0.43228255,\n",
       "        0.83529225, 0.9540428 , 0.57184261, 0.73234583, 1.28412142,\n",
       "        0.53317033, 0.2972419 , 0.35259303, 0.85768676, 0.47816848,\n",
       "        0.54997963, 0.60907467, 0.59788235, 2.14486022, 1.0166481 ,\n",
       "        0.41100361, 0.3506357 , 0.74280612, 0.48883895, 0.77167616,\n",
       "        0.507448  , 0.71019641, 0.65964015, 0.6808377 , 0.34858054,\n",
       "        0.45816975, 0.12139142, 0.42937086, 0.63498734, 0.82528301,\n",
       "        0.20677857, 0.44736545, 0.59622803, 0.40060595, 0.33044704]),\n",
       " 'mean_score_time': array([0.30573543, 0.3068006 , 0.52000093, 0.48756758, 0.5884343 ,\n",
       "        0.56326763, 0.78460153, 0.72280137, 0.90480153, 1.20120215,\n",
       "        0.71240131, 0.37960068, 0.52520092, 0.50960088, 0.57886783,\n",
       "        0.70200125, 0.86840161, 1.04000195, 1.00443522, 0.87490392,\n",
       "        0.43160073, 0.36546747, 0.52023451, 0.49400075, 0.55640101,\n",
       "        0.67080108, 0.8008016 , 0.8060015 , 0.85280148, 0.98530157,\n",
       "        0.561601  , 0.40040088, 0.53560106, 0.54080089, 0.79206816,\n",
       "        0.71240131, 0.70200141, 0.77003471, 0.94640183, 1.0608019 ,\n",
       "        0.55120095, 0.46966751, 0.69680119, 0.67600115, 0.67080124,\n",
       "        0.61880112, 0.93600154, 0.84240143, 1.10240197, 0.98800166,\n",
       "        0.57720113, 0.4368008 , 0.69120113, 0.57720105, 0.75400122,\n",
       "        0.66560125, 0.86320154, 0.79560129, 0.96950189, 0.76960127,\n",
       "        0.70720132, 0.46800089, 0.77460162, 0.55640101, 0.62920109,\n",
       "        0.60840114, 0.86133488, 0.7271359 , 0.95763508, 1.18560211,\n",
       "        0.59800108, 0.47840087, 0.79000155, 0.65686774, 0.79560137,\n",
       "        0.87693493, 1.50280253, 1.2065738 , 1.36004368, 1.14594992,\n",
       "        0.69417731, 0.61584282, 0.94540914, 0.55994137, 1.39938633,\n",
       "        0.69000173, 1.40841166, 1.12773673, 0.98791591, 1.38774459,\n",
       "        0.77104306, 0.57785916, 0.68230804, 0.75387065, 0.77400152,\n",
       "        0.96250232, 0.95643727, 1.52144241, 1.57590707, 1.31907209,\n",
       "        0.88160586, 0.47826989, 0.97240162, 1.0433476 , 1.39258154,\n",
       "        0.95251457, 1.53252363, 1.48175152, 1.50470662, 1.30417411,\n",
       "        0.68373473, 0.69873508, 1.06373898, 1.20830369, 1.19440158,\n",
       "        1.23307037, 1.74843351, 1.07299225, 1.54678949, 1.45738808,\n",
       "        0.72644432, 0.63417633, 1.03251584, 0.99708192, 1.15431714,\n",
       "        1.03781501, 1.28315131, 1.37718503, 1.6904912 , 1.3587807 ,\n",
       "        1.01630735, 0.63033509, 0.92136939, 0.89964223, 1.02763971,\n",
       "        1.06753945, 1.09287421, 1.06070447, 1.21326876, 1.51453678,\n",
       "        0.88236841, 0.70720124, 0.98640227, 0.87193672, 0.86933931,\n",
       "        0.96283491, 1.83560689, 1.77064991, 1.60006817, 1.37923861]),\n",
       " 'std_score_time': array([0.01418178, 0.00735378, 0.01945679, 0.0704777 , 0.02571185,\n",
       "        0.17564158, 0.08291652, 0.07677731, 0.13479952, 0.1626199 ,\n",
       "        0.12758588, 0.07677712, 0.03205518, 0.10216395, 0.11161795,\n",
       "        0.17832327, 0.06536327, 0.23635748, 0.12210012, 0.06626692,\n",
       "        0.09214438, 0.04299513, 0.12195332, 0.06536295, 0.13619648,\n",
       "        0.14689461, 0.04094493, 0.07782673, 0.10373978, 0.19195655,\n",
       "        0.25379041, 0.03205517, 0.02651492, 0.00735384, 0.1044541 ,\n",
       "        0.03205488, 0.06739978, 0.07727708, 0.17387019, 0.3550506 ,\n",
       "        0.14762898, 0.07865297, 0.02651495, 0.11766282, 0.03369974,\n",
       "        0.06019433, 0.26474121, 0.08824696, 0.36414926, 0.15088981,\n",
       "        0.17968289, 0.14354292, 0.1488497 , 0.14689452, 0.13379297,\n",
       "        0.06411006, 0.21553391, 0.05552095, 0.15283178, 0.08480946,\n",
       "        0.24478729, 0.06368679, 0.10613874, 0.12758574, 0.0367697 ,\n",
       "        0.07091869, 0.06503889, 0.0183517 , 0.19334408, 0.3420168 ,\n",
       "        0.11416365, 0.10295503, 0.28150375, 0.119371  , 0.32046581,\n",
       "        0.2333671 , 0.05743585, 0.14091593, 0.50965408, 0.35063866,\n",
       "        0.02348201, 0.05778399, 0.15268352, 0.22294214, 0.3452262 ,\n",
       "        0.068732  , 0.19484864, 0.40873021, 0.27184618, 0.13866256,\n",
       "        0.13690364, 0.17968449, 0.1194613 , 0.33590663, 0.26384103,\n",
       "        0.44402496, 0.23654853, 0.16424548, 0.33664656, 0.40790553,\n",
       "        0.11485901, 0.10108845, 0.06536306, 0.29394717, 0.52117922,\n",
       "        0.13033828, 0.12228914, 0.11264856, 0.46716461, 0.08385523,\n",
       "        0.05491202, 0.06576693, 0.29754131, 0.43982887, 0.15466191,\n",
       "        0.27052   , 0.01778356, 0.29303516, 0.43330596, 0.50474698,\n",
       "        0.30771307, 0.10352963, 0.18766388, 0.19181127, 0.0990258 ,\n",
       "        0.13516113, 0.06860009, 0.38355243, 0.58419846, 0.18503178,\n",
       "        0.17027638, 0.2190129 , 0.31957551, 0.2372239 , 0.0333436 ,\n",
       "        0.05733782, 0.28159672, 0.14347139, 0.03737291, 0.48239149,\n",
       "        0.18101941, 0.16574885, 0.33658699, 0.31563322, 0.1481752 ,\n",
       "        0.3013344 , 0.51282531, 0.55408263, 0.40504113, 0.19843572]),\n",
       " 'param_rf_clf__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,\n",
       "                    11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "                    12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14,\n",
       "                    14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_rf_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4),\n",
       "                    (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2),\n",
       "                    (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1),\n",
       "                    (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3),\n",
       "                    (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1),\n",
       "                    (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5),\n",
       "                    (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5),\n",
       "                    (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4),\n",
       "                    (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2),\n",
       "                    (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1),\n",
       "                    (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3),\n",
       "                    (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1),\n",
       "                    (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5),\n",
       "                    (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5),\n",
       "                    (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4),\n",
       "                    (1, 4), (1, 5), (1, 5)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_rf_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False}],\n",
       " 'split0_test_score': array([0.56118776, 0.56118776, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56088782, 0.56118776,\n",
       "        0.56088782, 0.56058788, 0.56088782, 0.56088782, 0.56118776,\n",
       "        0.56118776, 0.56118776, 0.56118776, 0.56088782, 0.56088782,\n",
       "        0.56088782, 0.56088782, 0.56088782, 0.56088782, 0.56088782,\n",
       "        0.5614877 , 0.56118776, 0.56088782, 0.56088782, 0.5614877 ,\n",
       "        0.5614877 , 0.56238752, 0.56118776, 0.56118776, 0.56118776,\n",
       "        0.56118776, 0.5614877 , 0.56268746, 0.56208758, 0.5614877 ,\n",
       "        0.56178764, 0.56088782, 0.5614877 , 0.56208758, 0.56118776,\n",
       "        0.56178764, 0.5614877 , 0.56238752, 0.56118776, 0.56178764,\n",
       "        0.56178764, 0.56208758, 0.5614877 , 0.5614877 , 0.56208758,\n",
       "        0.5614877 , 0.5614877 , 0.56388722, 0.56238752, 0.56268746,\n",
       "        0.5614877 , 0.56178764, 0.5614877 , 0.56178764, 0.56178764,\n",
       "        0.56478704, 0.56268746, 0.5629874 , 0.5629874 , 0.56388722,\n",
       "        0.56238752, 0.56268746, 0.56238752, 0.56268746, 0.56268746,\n",
       "        0.56568686, 0.56358728, 0.5644871 , 0.56388722, 0.56568686,\n",
       "        0.5629874 , 0.56388722, 0.56358728, 0.56208758, 0.56238752,\n",
       "        0.56688662, 0.56718656, 0.56538692, 0.56418716, 0.56508698,\n",
       "        0.56418716, 0.56478704, 0.56478704, 0.56268746, 0.56358728]),\n",
       " 'split1_test_score': array([0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56075608, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56135614,\n",
       "        0.56135614, 0.56105611, 0.56135614, 0.56105611, 0.56105611,\n",
       "        0.56165617, 0.56105611, 0.56105611, 0.56135614, 0.56075608,\n",
       "        0.56105611, 0.56135614, 0.56135614, 0.56135614, 0.56105611,\n",
       "        0.56045605, 0.56105611, 0.5619562 , 0.56225623, 0.56105611,\n",
       "        0.56255626, 0.56135614, 0.56165617, 0.56105611, 0.56105611,\n",
       "        0.5619562 , 0.56315632, 0.56105611, 0.56105611, 0.56255626,\n",
       "        0.56105611, 0.56285629, 0.5619562 , 0.56165617, 0.56135614,\n",
       "        0.5619562 , 0.56255626, 0.56345635, 0.56465647, 0.56165617,\n",
       "        0.56315632, 0.56075608, 0.56375638, 0.56045605, 0.56165617,\n",
       "        0.5649565 , 0.56315632, 0.56225623, 0.56165617, 0.56045605,\n",
       "        0.56105611, 0.56285629, 0.56255626, 0.56255626, 0.5619562 ,\n",
       "        0.56765677, 0.56435644, 0.56285629, 0.56675668, 0.56285629,\n",
       "        0.56285629, 0.56315632, 0.56255626, 0.56165617, 0.56135614,\n",
       "        0.56675668, 0.56525653, 0.5649565 , 0.56465647, 0.56255626,\n",
       "        0.56315632, 0.56165617, 0.56405641, 0.5649565 , 0.56225623,\n",
       "        0.56975698, 0.56765677, 0.56465647, 0.56375638, 0.5679568 ,\n",
       "        0.56615662, 0.56345635, 0.56435644, 0.56345635, 0.56315632]),\n",
       " 'split2_test_score': array([0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56135614, 0.56135614, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56135614, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56135614, 0.56135614, 0.56105611, 0.56105611, 0.56165617,\n",
       "        0.56225623, 0.56135614, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56285629, 0.56315632, 0.5619562 , 0.56225623, 0.56135614,\n",
       "        0.56315632, 0.56135614, 0.56255626, 0.5619562 , 0.56225623,\n",
       "        0.56255626, 0.56255626, 0.5619562 , 0.56285629, 0.56225623,\n",
       "        0.56225623, 0.56255626, 0.56225623, 0.56105611, 0.5619562 ,\n",
       "        0.56375638, 0.56285629, 0.56315632, 0.5619562 , 0.56225623,\n",
       "        0.56255626, 0.56285629, 0.56255626, 0.5619562 , 0.56255626,\n",
       "        0.56315632, 0.56525653, 0.56465647, 0.56225623, 0.56315632,\n",
       "        0.56435644, 0.56285629, 0.56225623, 0.56285629, 0.56285629,\n",
       "        0.56345635, 0.56555656, 0.56615662, 0.5649565 , 0.56345635,\n",
       "        0.5619562 , 0.56285629, 0.5619562 , 0.56225623, 0.56315632,\n",
       "        0.56375638, 0.56435644, 0.56465647, 0.56405641, 0.56405641,\n",
       "        0.5649565 , 0.56585659, 0.56315632, 0.56405641, 0.56465647,\n",
       "        0.56555656, 0.56585659, 0.56585659, 0.56555656, 0.56645665,\n",
       "        0.56615662, 0.56555656, 0.56315632, 0.56375638, 0.56405641]),\n",
       " 'mean_test_score': array([0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.561 , 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5612, 0.5612, 0.5611, 0.561 ,\n",
       "        0.5612, 0.5612, 0.5609, 0.5611, 0.561 , 0.5611, 0.5614, 0.5612,\n",
       "        0.5611, 0.5611, 0.5611, 0.5614, 0.5612, 0.5611, 0.5611, 0.561 ,\n",
       "        0.5616, 0.5618, 0.5616, 0.5618, 0.5613, 0.5624, 0.5617, 0.5618,\n",
       "        0.5614, 0.5615, 0.5619, 0.5624, 0.5619, 0.562 , 0.5621, 0.5617,\n",
       "        0.5621, 0.5619, 0.5616, 0.5615, 0.5625, 0.5623, 0.563 , 0.5626,\n",
       "        0.5619, 0.5625, 0.5619, 0.5626, 0.5613, 0.5621, 0.5632, 0.5633,\n",
       "        0.5636, 0.5621, 0.5621, 0.5623, 0.5625, 0.5621, 0.5624, 0.5622,\n",
       "        0.5653, 0.5642, 0.564 , 0.5649, 0.5634, 0.5624, 0.5629, 0.5623,\n",
       "        0.5622, 0.5624, 0.5654, 0.5644, 0.5647, 0.5642, 0.5641, 0.5637,\n",
       "        0.5638, 0.5636, 0.5637, 0.5631, 0.5674, 0.5669, 0.5653, 0.5645,\n",
       "        0.5665, 0.5655, 0.5646, 0.5641, 0.5633, 0.5636]),\n",
       " 'std_test_score': array([6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 1.80649266e-04, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        6.20667306e-05, 6.20667306e-05, 6.20667306e-05, 6.20667306e-05,\n",
       "        1.22785999e-04, 1.22785999e-04, 6.20667306e-05, 7.93334151e-05,\n",
       "        1.22785999e-04, 2.20775985e-04, 2.20733561e-04, 1.93695413e-04,\n",
       "        7.93334151e-05, 6.20667306e-05, 1.93728281e-04, 1.22785999e-04,\n",
       "        6.20667306e-05, 1.93695413e-04, 3.96900383e-04, 6.09283418e-04,\n",
       "        2.20775985e-04, 1.93695413e-04, 1.93695413e-04, 7.93334151e-05,\n",
       "        9.83058121e-04, 9.60493180e-04, 5.03661125e-04, 6.45103695e-04,\n",
       "        1.80618084e-04, 6.90126262e-04, 4.86224743e-04, 5.67879514e-04,\n",
       "        3.96916425e-04, 5.37386986e-04, 5.60110048e-04, 6.90126262e-04,\n",
       "        6.67199465e-04, 7.37489323e-04, 4.50013201e-04, 4.93827658e-04,\n",
       "        8.65972951e-04, 3.16261967e-04, 4.22977545e-04, 3.29798075e-04,\n",
       "        8.90986395e-04, 5.87379035e-04, 4.50135670e-04, 1.48749056e-03,\n",
       "        2.57526701e-04, 5.60186353e-04, 8.67566931e-04, 9.26721377e-04,\n",
       "        6.26625004e-04, 3.67546761e-04, 1.41650107e-03, 1.54200435e-03,\n",
       "        1.00067816e-03, 3.18359851e-04, 1.17801926e-03, 1.46464813e-03,\n",
       "        5.03788398e-04, 4.50013201e-04, 4.50054024e-04, 4.69103800e-04,\n",
       "        1.75268256e-03, 1.17654241e-03, 1.52578248e-03, 1.53935614e-03,\n",
       "        4.22770057e-04, 3.67547778e-04, 1.93892675e-04, 2.52660332e-04,\n",
       "        4.22908377e-04, 7.62485245e-04, 1.24149404e-03, 6.82178437e-04,\n",
       "        1.94090070e-04, 3.30053846e-04, 1.27846852e-03, 8.91082357e-04,\n",
       "        1.71583771e-03, 3.67551891e-04, 1.19806037e-03, 1.10180954e-03,\n",
       "        1.75274405e-03, 7.62315821e-04, 4.93764019e-04, 7.67464863e-04,\n",
       "        1.17202650e-03, 9.28455502e-04, 8.67508629e-04, 6.90006214e-04,\n",
       "        4.50176494e-04, 3.67551891e-04]),\n",
       " 'rank_test_score': array([ 79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,\n",
       "         79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,\n",
       "         79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,\n",
       "         79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79, 146,  79,\n",
       "         79,  79,  79,  79,  79,  79,  79,  79,  73,  73,  79, 146,  73,\n",
       "         73, 150,  79, 146,  79,  68,  73,  79,  79,  79,  68,  73,  79,\n",
       "         79, 146,  64,  58,  63,  58,  71,  36,  61,  58,  68,  66,  53,\n",
       "         36,  53,  52,  46,  61,  46,  53,  64,  66,  33,  41,  29,  31,\n",
       "         53,  33,  53,  31,  71,  46,  27,  25,  21,  46,  46,  41,  33,\n",
       "         46,  36,  44,   6,  14,  17,   8,  24,  36,  30,  41,  44,  36,\n",
       "          5,  12,   9,  13,  15,  19,  18,  21,  19,  28,   1,   2,   6,\n",
       "         11,   3,   4,  10,  15,  25,  21]),\n",
       " 'split0_train_score': array([0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56105611, 0.56105611,\n",
       "        0.56120612, 0.56105611, 0.56105611, 0.56120612, 0.56105611,\n",
       "        0.56105611, 0.56105611, 0.56105611, 0.56120612, 0.56105611,\n",
       "        0.56135614, 0.56180618, 0.56120612, 0.56135614, 0.56150615,\n",
       "        0.56165617, 0.56165617, 0.56210621, 0.56135614, 0.56105611,\n",
       "        0.56330633, 0.56270627, 0.56255626, 0.56105611, 0.56150615,\n",
       "        0.56210621, 0.56165617, 0.56240624, 0.56150615, 0.56225623,\n",
       "        0.56555656, 0.5630063 , 0.5619562 , 0.5630063 , 0.56330633,\n",
       "        0.56255626, 0.56435644, 0.5619562 , 0.56240624, 0.56270627,\n",
       "        0.56720672, 0.56810681, 0.56570657, 0.56390639, 0.56330633,\n",
       "        0.56405641, 0.56405641, 0.56420642, 0.56405641, 0.56210621,\n",
       "        0.57020702, 0.56765677, 0.56720672, 0.56510651, 0.56405641,\n",
       "        0.5649565 , 0.56540654, 0.56345635, 0.56285629, 0.56330633,\n",
       "        0.57560756, 0.57230723, 0.56750675, 0.56570657, 0.56540654,\n",
       "        0.56465647, 0.56480648, 0.56525653, 0.56360636, 0.56615662,\n",
       "        0.58025803, 0.57590759, 0.57140714, 0.56885689, 0.56825683,\n",
       "        0.56690669, 0.56690669, 0.56675668, 0.56660666, 0.56480648,\n",
       "        0.58625863, 0.58505851, 0.57425743, 0.57110711, 0.57080708,\n",
       "        0.56810681, 0.5679568 , 0.56840684, 0.56735674, 0.56720672,\n",
       "        0.59435944, 0.59480948, 0.57650765, 0.57635764, 0.57350735,\n",
       "        0.57275728, 0.57020702, 0.56945695, 0.5679568 , 0.56855686]),\n",
       " 'split1_train_score': array([0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56127194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56127194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.5620219 , 0.56142193, 0.56112194, 0.56127194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56127194, 0.56112194, 0.56112194,\n",
       "        0.56292185, 0.56427179, 0.5620219 , 0.56187191, 0.56112194,\n",
       "        0.56127194, 0.56127194, 0.56127194, 0.56127194, 0.56127194,\n",
       "        0.56412179, 0.56412179, 0.56262187, 0.56262187, 0.56247188,\n",
       "        0.56232188, 0.56127194, 0.56142193, 0.56127194, 0.56127194,\n",
       "        0.56892155, 0.56757162, 0.56547173, 0.56247188, 0.56517174,\n",
       "        0.5620219 , 0.56292185, 0.56187191, 0.56247188, 0.56157192,\n",
       "        0.57057147, 0.57312134, 0.5659217 , 0.56622169, 0.56307185,\n",
       "        0.56457177, 0.5639718 , 0.56307185, 0.56337183, 0.56142193,\n",
       "        0.58332083, 0.57567122, 0.56847158, 0.56727164, 0.56817159,\n",
       "        0.5659217 , 0.56382181, 0.56412179, 0.56232188, 0.5620219 ,\n",
       "        0.58767062, 0.58527074, 0.57042148, 0.57102145, 0.56727164,\n",
       "        0.56787161, 0.56562172, 0.56577171, 0.56562172, 0.56472176,\n",
       "        0.59232038, 0.59082046, 0.57372131, 0.57462127, 0.56817159,\n",
       "        0.56817159, 0.5660717 , 0.56907155, 0.56577171, 0.56577171,\n",
       "        0.5980201 , 0.60341983, 0.57477126, 0.57312134, 0.57492125,\n",
       "        0.57297135, 0.57027149, 0.56862157, 0.56742163, 0.56622169]),\n",
       " 'split2_train_score': array([0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56112194, 0.56157192, 0.56112194, 0.56112194, 0.56127194,\n",
       "        0.56142193, 0.56127194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56172191, 0.56142193, 0.56112194, 0.56112194, 0.56142193,\n",
       "        0.56217189, 0.56112194, 0.56112194, 0.56112194, 0.56112194,\n",
       "        0.56442178, 0.56727164, 0.56217189, 0.56247188, 0.56172191,\n",
       "        0.56292185, 0.56217189, 0.56187191, 0.56217189, 0.56262187,\n",
       "        0.56382181, 0.56367182, 0.56217189, 0.56277186, 0.56337183,\n",
       "        0.56322184, 0.56247188, 0.5620219 , 0.56157192, 0.56232188,\n",
       "        0.56637168, 0.56652167, 0.56442178, 0.56322184, 0.56277186,\n",
       "        0.56352182, 0.56217189, 0.56232188, 0.56352182, 0.56277186,\n",
       "        0.56832158, 0.57027149, 0.56352182, 0.56532173, 0.56382181,\n",
       "        0.56442178, 0.56322184, 0.56322184, 0.56247188, 0.56307185,\n",
       "        0.57432128, 0.57492125, 0.56847158, 0.56682166, 0.56517174,\n",
       "        0.56502175, 0.56322184, 0.56382181, 0.56442178, 0.56247188,\n",
       "        0.57897105, 0.57762112, 0.56787161, 0.56757162, 0.56562172,\n",
       "        0.56547173, 0.56547173, 0.56502175, 0.56412179, 0.56457177,\n",
       "        0.58302085, 0.58497075, 0.56937153, 0.56697165, 0.56817159,\n",
       "        0.56847158, 0.56832158, 0.56547173, 0.56412179, 0.56487176]),\n",
       " 'mean_train_score': array([0.5611    , 0.5611    , 0.5611    , 0.5611    , 0.5611    ,\n",
       "        0.5611    , 0.5611    , 0.5611    , 0.5611    , 0.5611    ,\n",
       "        0.5611    , 0.5611    , 0.5611    , 0.5611    , 0.5611    ,\n",
       "        0.5611    , 0.5611    , 0.5611    , 0.5611    , 0.5611    ,\n",
       "        0.5611    , 0.5611    , 0.5611    , 0.5611    , 0.5611    ,\n",
       "        0.5611    , 0.5611    , 0.5611    , 0.5611    , 0.5611    ,\n",
       "        0.5611    , 0.5611    , 0.5611    , 0.5611    , 0.5611    ,\n",
       "        0.5611    , 0.5611    , 0.5611    , 0.5611    , 0.5611    ,\n",
       "        0.5611    , 0.5611    , 0.56115   , 0.5611    , 0.5611    ,\n",
       "        0.5611    , 0.5611    , 0.5611    , 0.5611    , 0.5611    ,\n",
       "        0.5612    , 0.5611    , 0.5611    , 0.56115   , 0.5611    ,\n",
       "        0.5611    , 0.5611    , 0.5611    , 0.56115   , 0.5611    ,\n",
       "        0.56149999, 0.56160001, 0.56115   , 0.56125001, 0.56130001,\n",
       "        0.56140001, 0.56135002, 0.56150003, 0.56120001, 0.5611    ,\n",
       "        0.56265003, 0.5628    , 0.56190003, 0.56134999, 0.56135001,\n",
       "        0.56185001, 0.56135002, 0.56160004, 0.56130001, 0.56155004,\n",
       "        0.56470004, 0.56479991, 0.56224999, 0.56270002, 0.56250004,\n",
       "        0.5626    , 0.56260009, 0.56175001, 0.56195002, 0.56220003,\n",
       "        0.56665003, 0.56645008, 0.56445006, 0.56305004, 0.56394997,\n",
       "        0.56310005, 0.56315005, 0.56270008, 0.56270007, 0.56200001,\n",
       "        0.56905006, 0.56909993, 0.56585007, 0.56485001, 0.56330004,\n",
       "        0.56435003, 0.56385008, 0.56295003, 0.56324998, 0.56250004,\n",
       "        0.57574999, 0.57274998, 0.56650005, 0.56609998, 0.56579998,\n",
       "        0.56499998, 0.56395004, 0.56420005, 0.56280004, 0.56375012,\n",
       "        0.58074998, 0.57869986, 0.57010007, 0.5689    , 0.56690007,\n",
       "        0.56660002, 0.56525008, 0.56545007, 0.56555005, 0.56400004,\n",
       "        0.58585002, 0.58450003, 0.57195012, 0.5711    , 0.56820013,\n",
       "        0.56725004, 0.56650007, 0.56750005, 0.56575008, 0.56585007,\n",
       "        0.59180013, 0.59440002, 0.57355015, 0.57215021, 0.57220007,\n",
       "        0.57140007, 0.56960003, 0.56785008, 0.56650007, 0.5665501 ]),\n",
       " 'std_train_score': array([3.10364686e-05, 3.10364686e-05, 3.10364686e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 3.10364686e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 3.10364686e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 3.10364686e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 3.10364686e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 3.10364686e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 3.10364686e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 3.10364686e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 3.10364686e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 3.10364686e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 9.03175644e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 3.10364686e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 6.13869213e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.96812813e-05, 3.10364686e-05, 3.10364686e-05,\n",
       "        3.10364686e-05, 3.10364686e-05, 3.96812813e-05, 3.10364686e-05,\n",
       "        3.81226897e-04, 1.58122495e-04, 3.96812813e-05, 9.68578653e-05,\n",
       "        1.58102936e-04, 2.18644988e-04, 2.24974734e-04, 4.32986039e-04,\n",
       "        1.10399031e-04, 3.10364686e-05, 6.74788422e-04, 1.16533549e-03,\n",
       "        5.91862055e-04, 3.70031436e-04, 1.64890231e-04, 4.09640282e-04,\n",
       "        2.24974734e-04, 5.73349020e-04, 1.58102936e-04, 5.03092441e-04,\n",
       "        6.17904211e-04, 1.80612915e-03, 2.77313571e-04, 2.25066595e-04,\n",
       "        6.47141920e-04, 2.46881935e-04, 1.29513140e-03, 2.34526792e-04,\n",
       "        4.88931332e-04, 6.57161918e-04, 2.11884874e-03, 1.97664364e-03,\n",
       "        1.61376097e-03, 6.17789848e-04, 8.64338138e-04, 8.35036613e-04,\n",
       "        6.66701689e-04, 1.06690569e-03, 1.02704072e-03, 3.15246586e-04,\n",
       "        1.89973355e-03, 2.88108184e-03, 1.13807555e-03, 1.23804102e-03,\n",
       "        5.48675351e-04, 6.06326416e-04, 1.32334209e-03, 4.71084661e-04,\n",
       "        2.85039257e-04, 7.92951238e-04, 6.12424638e-03, 2.22655037e-03,\n",
       "        2.14244357e-03, 8.43250980e-04, 1.79745154e-03, 6.58759841e-04,\n",
       "        6.53251005e-04, 8.32498601e-04, 5.73433391e-04, 1.75480527e-03,\n",
       "        5.46093280e-03, 4.66372701e-03, 1.21979901e-03, 1.71482808e-03,\n",
       "        1.28659334e-03, 1.18348617e-03, 1.52711453e-03, 1.21954988e-03,\n",
       "        8.93412593e-04, 1.08112841e-03, 5.45749568e-03, 5.40305886e-03,\n",
       "        2.89223447e-03, 2.87801094e-03, 2.11701127e-03, 1.25773768e-03,\n",
       "        1.05877983e-03, 1.77330639e-03, 1.32074802e-03, 1.07713948e-03,\n",
       "        6.38523915e-03, 7.53736731e-03, 3.03857297e-03, 3.89285678e-03,\n",
       "        2.90645630e-03, 2.07259961e-03, 9.04381155e-04, 1.71598158e-03,\n",
       "        1.69582995e-03, 1.52225265e-03])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf = GridSearchCV(random_forest_ngram, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.21466724, 0.51756795, 0.48610075, 1.2676398 , 0.81457019,\n",
       "        1.08333596, 1.07806842, 1.23323576, 1.62240275, 1.70560304,\n",
       "        1.66920288, 1.81480328, 2.15780393, 2.20730392, 2.19440389,\n",
       "        2.31400402, 2.67697144, 2.70154881, 2.75957529, 2.18503348]),\n",
       " 'std_fit_time': array([0.02853296, 0.28727248, 0.30143675, 0.70022693, 0.1047248 ,\n",
       "        0.09148916, 0.09711389, 0.19668594, 0.18502112, 0.10295501,\n",
       "        0.09185041, 0.2768242 , 0.25034312, 0.2191421 , 0.19162573,\n",
       "        0.88854753, 0.75111219, 0.76239049, 0.90318539, 0.26235729]),\n",
       " 'mean_score_time': array([0.09360027, 0.1092004 , 0.10400033, 0.09570034, 0.18013374,\n",
       "        0.17680041, 0.17680025, 0.16640011, 0.20280043, 0.20800018,\n",
       "        0.20280035, 0.20800042, 0.24960041, 0.23920051, 0.24440034,\n",
       "        0.24960033, 0.2772673 , 0.29050342, 0.29000457, 0.2772034 ]),\n",
       " 'std_score_time': array([1.27375136e-02, 1.12391596e-07, 7.35395072e-03, 2.97011651e-03,\n",
       "        6.45256689e-03, 7.35383832e-03, 7.35395072e-03, 7.35389452e-03,\n",
       "        1.27374163e-02, 7.35395072e-03, 1.27372216e-02, 7.35395072e-03,\n",
       "        1.27373189e-02, 7.35400691e-03, 1.94566823e-02, 1.27374163e-02,\n",
       "        1.70648656e-02, 1.42197350e-02, 1.24165432e-02, 2.71646881e-02]),\n",
       " 'param_LogR_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 5), (1, 5)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_LogR_tfidf__smooth_idf': masked_array(data=[True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_LogR_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False}],\n",
       " 'split0_test_score': array([0.61937612, 0.61367726, 0.61907618, 0.61367726, 0.619976  ,\n",
       "        0.6124775 , 0.62027594, 0.6124775 , 0.619976  , 0.61307738,\n",
       "        0.61877624, 0.61307738, 0.6169766 , 0.61307738, 0.6169766 ,\n",
       "        0.61307738, 0.61637672, 0.61427714, 0.61907618, 0.61427714]),\n",
       " 'split1_test_score': array([0.60246025, 0.60756076, 0.60186019, 0.60756076, 0.60546055,\n",
       "        0.60876088, 0.60576058, 0.60876088, 0.6069607 , 0.60936094,\n",
       "        0.6069607 , 0.60936094, 0.60546055, 0.60966097, 0.60876088,\n",
       "        0.60966097, 0.60906091, 0.61056106, 0.60816082, 0.61056106]),\n",
       " 'split2_test_score': array([0.59465947, 0.59285929, 0.59405941, 0.59285929, 0.60216022,\n",
       "        0.59705971, 0.6009601 , 0.59705971, 0.60546055, 0.60336034,\n",
       "        0.60756076, 0.60336034, 0.60786079, 0.60366037, 0.60966097,\n",
       "        0.60366037, 0.61026103, 0.60606061, 0.61056106, 0.60606061]),\n",
       " 'mean_test_score': array([0.6055, 0.6047, 0.605 , 0.6047, 0.6092, 0.6061, 0.609 , 0.6061,\n",
       "        0.6108, 0.6086, 0.6111, 0.6086, 0.6101, 0.6088, 0.6118, 0.6088,\n",
       "        0.6119, 0.6103, 0.6126, 0.6103]),\n",
       " 'std_test_score': array([0.01031714, 0.00873649, 0.0104518 , 0.00873649, 0.0077391 ,\n",
       "        0.0065696 , 0.00821176, 0.0065696 , 0.00651822, 0.00400339,\n",
       "        0.00543426, 0.00400339, 0.00496095, 0.00389247, 0.00367935,\n",
       "        0.00389247, 0.00320368, 0.00335955, 0.00468368, 0.00335955]),\n",
       " 'rank_test_score': array([17, 19, 18, 19,  9, 15, 10, 15,  5, 13,  4, 13,  8, 11,  3, 11,  2,\n",
       "         6,  1,  6]),\n",
       " 'split0_train_score': array([0.8139814 , 0.77122712, 0.81818182, 0.77122712, 0.90549055,\n",
       "        0.85193519, 0.91224122, 0.85193519, 0.93549355, 0.88283828,\n",
       "        0.94194419, 0.88283828, 0.95139514, 0.89888989, 0.95664566,\n",
       "        0.89888989, 0.95994599, 0.90864086, 0.96519652, 0.90864086]),\n",
       " 'split1_train_score': array([0.80740963, 0.76841158, 0.8119094 , 0.76841158, 0.89560522,\n",
       "        0.84625769, 0.90220489, 0.84625769, 0.92770361, 0.87355632,\n",
       "        0.93445328, 0.87355632, 0.94510274, 0.88855557, 0.95080246,\n",
       "        0.88855557, 0.9559022 , 0.89890505, 0.96130193, 0.89890505]),\n",
       " 'split2_train_score': array([0.81370931, 0.7739613 , 0.8159592 , 0.7739613 , 0.90550472,\n",
       "        0.8519574 , 0.91075446, 0.8519574 , 0.93535323, 0.88225589,\n",
       "        0.94105295, 0.88225589, 0.94840258, 0.89665517, 0.9559022 ,\n",
       "        0.89665517, 0.95965202, 0.90610469, 0.9640018 , 0.90610469]),\n",
       " 'mean_train_score': array([0.81170011, 0.7712    , 0.81535014, 0.7712    , 0.90220016,\n",
       "        0.85005009, 0.90840019, 0.85005009, 0.93285013, 0.87955016,\n",
       "        0.93915014, 0.87955016, 0.94830015, 0.89470021, 0.95445011,\n",
       "        0.89470021, 0.95850007, 0.9045502 , 0.96350008, 0.9045502 ]),\n",
       " 'std_train_score': array([0.00303586, 0.00226575, 0.00259667, 0.00226575, 0.00466333,\n",
       "        0.00268165, 0.00442259, 0.00268165, 0.00363959, 0.00424495,\n",
       "        0.00334105, 0.00424495, 0.00256988, 0.00443966, 0.00259707,\n",
       "        0.00443966, 0.00184089, 0.00412382, 0.00162906, 0.00412382])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression parameters\n",
    "parameters = {'LogR_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'LogR_tfidf__use_idf': (True, False),\n",
    "               'LogR_tfidf__smooth_idf': (True, False)\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(logR_pipeline_ngram, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000000002A36540, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\P...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000000002A36540, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\P...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(584, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(584, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (584, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=584, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 14, 6, 41, 57, 613098, tzinfo=tzutc()), 'msg_id': '4a08f60f01d0451b81be92408c12a167', 'msg_type': 'execute_request', 'session': 'b88ae4e95f474be1876d1446f51eb304', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '4a08f60f01d0451b81be92408c12a167', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'b88ae4e95f474be1876d1446f51eb304']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 14, 6, 41, 57, 613098, tzinfo=tzutc()), 'msg_id': '4a08f60f01d0451b81be92408c12a167', 'msg_type': 'execute_request', 'session': 'b88ae4e95f474be1876d1446f51eb304', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '4a08f60f01d0451b81be92408c12a167', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'b88ae4e95f474be1876d1446f51eb304'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 14, 6, 41, 57, 613098, tzinfo=tzutc()), 'msg_id': '4a08f60f01d0451b81be92408c12a167', 'msg_type': 'execute_request', 'session': 'b88ae4e95f474be1876d1446f51eb304', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '4a08f60f01d0451b81be92408c12a167', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-24-ffd071b0f211>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1021cf60, execution_c...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000000001C13E4B0, file \"<ipython-input-24-ffd071b0f211>\", line 9>\n        result = <ExecutionResult object at 1021cf60, execution_c...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000000001C13E4B0, file \"<ipython-input-24-ffd071b0f211>\", line 9>, result=<ExecutionResult object at 1021cf60, execution_c...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000000001C13E4B0, file \"<ipython-input-24-ffd071b0f211>\", line 9>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport csv\\nimport numpy as n...okenize import word_tokenize\\nimport seaborn as sb', \"test_filename = 'test.csv'\\ntrain_filename = 'tra...machinelearning\\\\csvfiles\\\\liar_dataset\\\\valid.csv')\", 'def data_obs():\\n    print(\"training dataset size...turn [porter.stem(word) for word in text.split()]', '#show the distribution of labels in the train an... in data_TrainNews.iterrows():\\n    print(row)\\n\"\"\"', 'import pandas as pd\\nimport numpy as np\\nfrom skle...enize\\nfrom gensim.models.word2vec import Word2Vec', \"countV = CountVectorizer()\\ntrain_count = countV....ement'].values)\\n\\nprint(countV)\\nprint(train_count)\", 'def get_countVectorizer_stats():\\n    \\n    #vocab... names\\n    print(countV.get_feature_names()[:25])', '#tf-idf \\ntfidfV = TfidfTransformer()\\ntrain_tfidf...data feature names \\n    print(train_tfidf.A[:10])', \"tfidf_ngram = TfidfVectorizer(stop_words='english',ngram_range=(1,4),use_idf=True,smooth_idf=True)\", \"#bag of words - with n-grams\\ncountV_ngram = Coun...',ngram_range=(1,4),use_idf=True,smooth_idf=True)\", 'def features(sentence, index):\\n    \"\"\" sentence:...ex][1:].lower() != sentence[index][1:]\\n    }\\n    ', 'def untag(tagged_sentence):\\n    return [w for w, t in tagged_sentence]', \"#POS Tagging\\ntagged_sentences = nltk.corpus.tree...train_news['Statement']\\nprint(training_sentences)\", '#Using Word2Vec \\nimport numpy as np\\ndef loadGlov... line.split()[1:]))\\n           for line in lines}', 'class MeanEmbeddingVectorizer(object):\\n    def _...               for words in X\\n            ])\\n\\n\"\"\"', 'import numpy as np\\nimport pandas as pd\\nimport pi...om sklearn.metrics import average_precision_score', \"#string to test\\ndoc_new = ['obama is running for president in 2016']\", '#Using bag of words\\n#building classifier using n...d_pipeline)\\nbuild_confusion_matrix(random_forest)', '##Now using n-grams\\n#naive-bayes classifier\\nnb_p...gram)\\nbuild_confusion_matrix(random_forest_ngram)', ...], 'KFold': <class 'sklearn.cross_validation.KFold'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MeanEmbeddingVectorizer': <class '__main__.MeanEmbeddingVectorizer'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {4: '#converting multiclass labels present in our dat...row in data_TrainNews.iterrows():\\n    print(row)\\n', 15: '\\nclass TfidfEmbeddingVectorizer(object):\\n    def...)\\n                for words in X\\n            ])\\n\\n', 18: (None, None, None, None, None), 22: {'mean_fit_time': array([1.02366885e+00, 1.31106...075e-03,\n       1.99449338e-03, 2.11728018e-03])}, 23: {'mean_fit_time': array([0.28060047, 1.39943592,...0.00184089, 0.00412382, 0.00162906, 0.00412382])}}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'PorterStemmer': <class 'nltk.stem.porter.PorterStemmer'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport csv\\nimport numpy as n...okenize import word_tokenize\\nimport seaborn as sb', \"test_filename = 'test.csv'\\ntrain_filename = 'tra...machinelearning\\\\csvfiles\\\\liar_dataset\\\\valid.csv')\", 'def data_obs():\\n    print(\"training dataset size...turn [porter.stem(word) for word in text.split()]', '#show the distribution of labels in the train an... in data_TrainNews.iterrows():\\n    print(row)\\n\"\"\"', 'import pandas as pd\\nimport numpy as np\\nfrom skle...enize\\nfrom gensim.models.word2vec import Word2Vec', \"countV = CountVectorizer()\\ntrain_count = countV....ement'].values)\\n\\nprint(countV)\\nprint(train_count)\", 'def get_countVectorizer_stats():\\n    \\n    #vocab... names\\n    print(countV.get_feature_names()[:25])', '#tf-idf \\ntfidfV = TfidfTransformer()\\ntrain_tfidf...data feature names \\n    print(train_tfidf.A[:10])', \"tfidf_ngram = TfidfVectorizer(stop_words='english',ngram_range=(1,4),use_idf=True,smooth_idf=True)\", \"#bag of words - with n-grams\\ncountV_ngram = Coun...',ngram_range=(1,4),use_idf=True,smooth_idf=True)\", 'def features(sentence, index):\\n    \"\"\" sentence:...ex][1:].lower() != sentence[index][1:]\\n    }\\n    ', 'def untag(tagged_sentence):\\n    return [w for w, t in tagged_sentence]', \"#POS Tagging\\ntagged_sentences = nltk.corpus.tree...train_news['Statement']\\nprint(training_sentences)\", '#Using Word2Vec \\nimport numpy as np\\ndef loadGlov... line.split()[1:]))\\n           for line in lines}', 'class MeanEmbeddingVectorizer(object):\\n    def _...               for words in X\\n            ])\\n\\n\"\"\"', 'import numpy as np\\nimport pandas as pd\\nimport pi...om sklearn.metrics import average_precision_score', \"#string to test\\ndoc_new = ['obama is running for president in 2016']\", '#Using bag of words\\n#building classifier using n...d_pipeline)\\nbuild_confusion_matrix(random_forest)', '##Now using n-grams\\n#naive-bayes classifier\\nnb_p...gram)\\nbuild_confusion_matrix(random_forest_ngram)', ...], 'KFold': <class 'sklearn.cross_validation.KFold'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MeanEmbeddingVectorizer': <class '__main__.MeanEmbeddingVectorizer'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {4: '#converting multiclass labels present in our dat...row in data_TrainNews.iterrows():\\n    print(row)\\n', 15: '\\nclass TfidfEmbeddingVectorizer(object):\\n    def...)\\n                for words in X\\n            ])\\n\\n', 18: (None, None, None, None, None), 22: {'mean_fit_time': array([1.02366885e+00, 1.31106...075e-03,\n       1.99449338e-03, 2.11728018e-03])}, 23: {'mean_fit_time': array([0.28060047, 1.39943592,...0.00184089, 0.00412382, 0.00162906, 0.00412382])}}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'PorterStemmer': <class 'nltk.stem.porter.PorterStemmer'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\PB\\<ipython-input-24-ffd071b0f211> in <module>()\n      4                'svm_tfidf__smooth_idf': (True, False),\n      5                'svm_clf__penalty': ('l1','l2'),\n      6 }\n      7 \n      8 gs_clf = GridSearchCV(svm_pipeline_ngram, parameters, n_jobs=-1)\n----> 9 gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n     10 \n     11 gs_clf.best_score_\n     12 gs_clf.best_params_\n     13 gs_clf.cv_results_\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=0), X=0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, y=0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = 0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object\n        y = 0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Nov 13 22:42:06 2018\nPID: 1820                    Python 3.6.5: C:\\Users\\PB\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), 0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, 0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, {'score': <function _passthrough_scorer>}, array([3282, 3283, 3285, ..., 9997, 9998, 9999]), array([   0,    1,    2, ..., 3369, 3371, 3372]), 0, {'svm_clf__penalty': 'l1', 'svm_tfidf__ngram_range': (1, 1), 'svm_tfidf__smooth_idf': True, 'svm_tfidf__use_idf': True}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), 0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, 0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, {'score': <function _passthrough_scorer>}, array([3282, 3283, 3285, ..., 9997, 9998, 9999]), array([   0,    1,    2, ..., 3369, 3371, 3372]), 0, {'svm_clf__penalty': 'l1', 'svm_tfidf__ngram_range': (1, 1), 'svm_tfidf__smooth_idf': True, 'svm_tfidf__use_idf': True})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), X=0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, y=0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, scorer={'score': <function _passthrough_scorer>}, train=array([3282, 3283, 3285, ..., 9997, 9998, 9999]), test=array([   0,    1,    2, ..., 3369, 3371, 3372]), verbose=0, parameters={'svm_clf__penalty': 'l1', 'svm_tfidf__ngram_range': (1, 1), 'svm_tfidf__smooth_idf': True, 'svm_tfidf__use_idf': True}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...andom_state=None, tol=0.0001,\n     verbose=0))])>\n        X_train = 3282    Without Westside MAX, wed need to add 2....ple.\nName: Statement, Length: 6666, dtype: object\n        y_train = 3282    False\n3283    False\n3285    False\n3286  ...9     True\nName: Label, Length: 6666, dtype: bool\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), X=3282    Without Westside MAX, wed need to add 2....ple.\nName: Statement, Length: 6666, dtype: object, y=3282    False\n3283    False\n3285    False\n3286  ...9     True\nName: Label, Length: 6666, dtype: bool, **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LinearSVC.fit of LinearSVC(C=1.0, ..., random_state=None, tol=0.0001,\n     verbose=0)>\n        Xt = <6666x9715 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = 3282    False\n3283    False\n3285    False\n3286  ...9     True\nName: Label, Length: 6666, dtype: bool\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\classes.py in fit(self=LinearSVC(C=1.0, class_weight=None, dual=True, f...', random_state=None, tol=0.0001,\n     verbose=0), X=<6666x9715 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ...,  True, False,  True]), sample_weight=None)\n    230 \n    231         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n    232             X, y, self.C, self.fit_intercept, self.intercept_scaling,\n    233             self.class_weight, self.penalty, self.dual, self.verbose,\n    234             self.max_iter, self.tol, self.random_state, self.multi_class,\n--> 235             self.loss, sample_weight=sample_weight)\n        self.loss = 'squared_hinge'\n        sample_weight = None\n    236 \n    237         if self.multi_class == \"crammer_singer\" and len(self.classes_) == 2:\n    238             self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)\n    239             if self.fit_intercept:\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py in _fit_liblinear(X=<6666x9715 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ...,  True, False,  True]), C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, penalty='l1', dual=True, verbose=0, max_iter=1000, tol=0.0001, random_state=None, multi_class='ovr', loss='squared_hinge', epsilon=0.1, sample_weight=array([1., 1., 1., ..., 1., 1., 1.]))\n    881         sample_weight = np.ones(X.shape[0])\n    882     else:\n    883         sample_weight = np.array(sample_weight, dtype=np.float64, order='C')\n    884         check_consistent_length(sample_weight, X)\n    885 \n--> 886     solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n        solver_type = undefined\n        multi_class = 'ovr'\n        penalty = 'l1'\n        loss = 'squared_hinge'\n        dual = True\n    887     raw_coef_, n_iter_ = liblinear.train_wrap(\n    888         X, y_ind, sp.isspmatrix(X), solver_type, tol, bias, C,\n    889         class_weight_, max_iter, rnd.randint(np.iinfo('i').max),\n    890         epsilon, sample_weight)\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py in _get_liblinear_solver_type(multi_class='ovr', penalty='l1', loss='squared_hinge', dual=True)\n    742                                 % (penalty, loss, dual))\n    743             else:\n    744                 return solver_num\n    745     raise ValueError('Unsupported set of arguments: %s, '\n    746                      'Parameters: penalty=%r, loss=%r, dual=%r'\n--> 747                      % (error_string, penalty, loss, dual))\n        error_string = \"The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True\"\n        penalty = 'l1'\n        loss = 'squared_hinge'\n        dual = True\n    748 \n    749 \n    750 def _fit_liblinear(X, y, C, fit_intercept, intercept_scaling, class_weight,\n    751                    penalty, dual, verbose, max_iter, tol,\n\nValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 250, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\classes.py\", line 235, in fit\n    self.loss, sample_weight=sample_weight)\n  File \"C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\", line 886, in _fit_liblinear\n    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n  File \"C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\", line 747, in _get_liblinear_solver_type\n    % (error_string, penalty, loss, dual))\nValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\PB\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Nov 13 22:42:06 2018\nPID: 1820                    Python 3.6.5: C:\\Users\\PB\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), 0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, 0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, {'score': <function _passthrough_scorer>}, array([3282, 3283, 3285, ..., 9997, 9998, 9999]), array([   0,    1,    2, ..., 3369, 3371, 3372]), 0, {'svm_clf__penalty': 'l1', 'svm_tfidf__ngram_range': (1, 1), 'svm_tfidf__smooth_idf': True, 'svm_tfidf__use_idf': True}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), 0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, 0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, {'score': <function _passthrough_scorer>}, array([3282, 3283, 3285, ..., 9997, 9998, 9999]), array([   0,    1,    2, ..., 3369, 3371, 3372]), 0, {'svm_clf__penalty': 'l1', 'svm_tfidf__ngram_range': (1, 1), 'svm_tfidf__smooth_idf': True, 'svm_tfidf__use_idf': True})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), X=0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, y=0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, scorer={'score': <function _passthrough_scorer>}, train=array([3282, 3283, 3285, ..., 9997, 9998, 9999]), test=array([   0,    1,    2, ..., 3369, 3371, 3372]), verbose=0, parameters={'svm_clf__penalty': 'l1', 'svm_tfidf__ngram_range': (1, 1), 'svm_tfidf__smooth_idf': True, 'svm_tfidf__use_idf': True}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...andom_state=None, tol=0.0001,\n     verbose=0))])>\n        X_train = 3282    Without Westside MAX, wed need to add 2....ple.\nName: Statement, Length: 6666, dtype: object\n        y_train = 3282    False\n3283    False\n3285    False\n3286  ...9     True\nName: Label, Length: 6666, dtype: bool\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), X=3282    Without Westside MAX, wed need to add 2....ple.\nName: Statement, Length: 6666, dtype: object, y=3282    False\n3283    False\n3285    False\n3286  ...9     True\nName: Label, Length: 6666, dtype: bool, **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LinearSVC.fit of LinearSVC(C=1.0, ..., random_state=None, tol=0.0001,\n     verbose=0)>\n        Xt = <6666x9715 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = 3282    False\n3283    False\n3285    False\n3286  ...9     True\nName: Label, Length: 6666, dtype: bool\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\classes.py in fit(self=LinearSVC(C=1.0, class_weight=None, dual=True, f...', random_state=None, tol=0.0001,\n     verbose=0), X=<6666x9715 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ...,  True, False,  True]), sample_weight=None)\n    230 \n    231         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n    232             X, y, self.C, self.fit_intercept, self.intercept_scaling,\n    233             self.class_weight, self.penalty, self.dual, self.verbose,\n    234             self.max_iter, self.tol, self.random_state, self.multi_class,\n--> 235             self.loss, sample_weight=sample_weight)\n        self.loss = 'squared_hinge'\n        sample_weight = None\n    236 \n    237         if self.multi_class == \"crammer_singer\" and len(self.classes_) == 2:\n    238             self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)\n    239             if self.fit_intercept:\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py in _fit_liblinear(X=<6666x9715 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ...,  True, False,  True]), C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, penalty='l1', dual=True, verbose=0, max_iter=1000, tol=0.0001, random_state=None, multi_class='ovr', loss='squared_hinge', epsilon=0.1, sample_weight=array([1., 1., 1., ..., 1., 1., 1.]))\n    881         sample_weight = np.ones(X.shape[0])\n    882     else:\n    883         sample_weight = np.array(sample_weight, dtype=np.float64, order='C')\n    884         check_consistent_length(sample_weight, X)\n    885 \n--> 886     solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n        solver_type = undefined\n        multi_class = 'ovr'\n        penalty = 'l1'\n        loss = 'squared_hinge'\n        dual = True\n    887     raw_coef_, n_iter_ = liblinear.train_wrap(\n    888         X, y_ind, sp.isspmatrix(X), solver_type, tol, bias, C,\n    889         class_weight_, max_iter, rnd.randint(np.iinfo('i').max),\n    890         epsilon, sample_weight)\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py in _get_liblinear_solver_type(multi_class='ovr', penalty='l1', loss='squared_hinge', dual=True)\n    742                                 % (penalty, loss, dual))\n    743             else:\n    744                 return solver_num\n    745     raise ValueError('Unsupported set of arguments: %s, '\n    746                      'Parameters: penalty=%r, loss=%r, dual=%r'\n--> 747                      % (error_string, penalty, loss, dual))\n        error_string = \"The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True\"\n        penalty = 'l1'\n        loss = 'squared_hinge'\n        dual = True\n    748 \n    749 \n    750 def _fit_liblinear(X, y, C, fit_intercept, intercept_scaling, class_weight,\n    751                    penalty, dual, verbose, max_iter, tol,\n\nValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Nov 13 22:42:06 2018\nPID: 1820                    Python 3.6.5: C:\\Users\\PB\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), 0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, 0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, {'score': <function _passthrough_scorer>}, array([3282, 3283, 3285, ..., 9997, 9998, 9999]), array([   0,    1,    2, ..., 3369, 3371, 3372]), 0, {'svm_clf__penalty': 'l1', 'svm_tfidf__ngram_range': (1, 1), 'svm_tfidf__smooth_idf': True, 'svm_tfidf__use_idf': True}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), 0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, 0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, {'score': <function _passthrough_scorer>}, array([3282, 3283, 3285, ..., 9997, 9998, 9999]), array([   0,    1,    2, ..., 3369, 3371, 3372]), 0, {'svm_clf__penalty': 'l1', 'svm_tfidf__ngram_range': (1, 1), 'svm_tfidf__smooth_idf': True, 'svm_tfidf__use_idf': True})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), X=0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, y=0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, scorer={'score': <function _passthrough_scorer>}, train=array([3282, 3283, 3285, ..., 9997, 9998, 9999]), test=array([   0,    1,    2, ..., 3369, 3371, 3372]), verbose=0, parameters={'svm_clf__penalty': 'l1', 'svm_tfidf__ngram_range': (1, 1), 'svm_tfidf__smooth_idf': True, 'svm_tfidf__use_idf': True}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...andom_state=None, tol=0.0001,\n     verbose=0))])>\n        X_train = 3282    Without Westside MAX, wed need to add 2....ple.\nName: Statement, Length: 6666, dtype: object\n        y_train = 3282    False\n3283    False\n3285    False\n3286  ...9     True\nName: Label, Length: 6666, dtype: bool\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), X=3282    Without Westside MAX, wed need to add 2....ple.\nName: Statement, Length: 6666, dtype: object, y=3282    False\n3283    False\n3285    False\n3286  ...9     True\nName: Label, Length: 6666, dtype: bool, **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LinearSVC.fit of LinearSVC(C=1.0, ..., random_state=None, tol=0.0001,\n     verbose=0)>\n        Xt = <6666x9715 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = 3282    False\n3283    False\n3285    False\n3286  ...9     True\nName: Label, Length: 6666, dtype: bool\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\classes.py in fit(self=LinearSVC(C=1.0, class_weight=None, dual=True, f...', random_state=None, tol=0.0001,\n     verbose=0), X=<6666x9715 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ...,  True, False,  True]), sample_weight=None)\n    230 \n    231         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n    232             X, y, self.C, self.fit_intercept, self.intercept_scaling,\n    233             self.class_weight, self.penalty, self.dual, self.verbose,\n    234             self.max_iter, self.tol, self.random_state, self.multi_class,\n--> 235             self.loss, sample_weight=sample_weight)\n        self.loss = 'squared_hinge'\n        sample_weight = None\n    236 \n    237         if self.multi_class == \"crammer_singer\" and len(self.classes_) == 2:\n    238             self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)\n    239             if self.fit_intercept:\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py in _fit_liblinear(X=<6666x9715 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ...,  True, False,  True]), C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, penalty='l1', dual=True, verbose=0, max_iter=1000, tol=0.0001, random_state=None, multi_class='ovr', loss='squared_hinge', epsilon=0.1, sample_weight=array([1., 1., 1., ..., 1., 1., 1.]))\n    881         sample_weight = np.ones(X.shape[0])\n    882     else:\n    883         sample_weight = np.array(sample_weight, dtype=np.float64, order='C')\n    884         check_consistent_length(sample_weight, X)\n    885 \n--> 886     solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n        solver_type = undefined\n        multi_class = 'ovr'\n        penalty = 'l1'\n        loss = 'squared_hinge'\n        dual = True\n    887     raw_coef_, n_iter_ = liblinear.train_wrap(\n    888         X, y_ind, sp.isspmatrix(X), solver_type, tol, bias, C,\n    889         class_weight_, max_iter, rnd.randint(np.iinfo('i').max),\n    890         epsilon, sample_weight)\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py in _get_liblinear_solver_type(multi_class='ovr', penalty='l1', loss='squared_hinge', dual=True)\n    742                                 % (penalty, loss, dual))\n    743             else:\n    744                 return solver_num\n    745     raise ValueError('Unsupported set of arguments: %s, '\n    746                      'Parameters: penalty=%r, loss=%r, dual=%r'\n--> 747                      % (error_string, penalty, loss, dual))\n        error_string = \"The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True\"\n        penalty = 'l1'\n        loss = 'squared_hinge'\n        dual = True\n    748 \n    749 \n    750 def _fit_liblinear(X, y, C, fit_intercept, intercept_scaling, class_weight,\n    751                    penalty, dual, verbose, max_iter, tol,\n\nValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ffd071b0f211>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgs_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_pipeline_ngram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgs_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_news\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Statement'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_news\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000000002A36540, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\P...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000000002A36540, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\P...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(584, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(584, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (584, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=584, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 14, 6, 41, 57, 613098, tzinfo=tzutc()), 'msg_id': '4a08f60f01d0451b81be92408c12a167', 'msg_type': 'execute_request', 'session': 'b88ae4e95f474be1876d1446f51eb304', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '4a08f60f01d0451b81be92408c12a167', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'b88ae4e95f474be1876d1446f51eb304']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 14, 6, 41, 57, 613098, tzinfo=tzutc()), 'msg_id': '4a08f60f01d0451b81be92408c12a167', 'msg_type': 'execute_request', 'session': 'b88ae4e95f474be1876d1446f51eb304', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '4a08f60f01d0451b81be92408c12a167', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'b88ae4e95f474be1876d1446f51eb304'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 14, 6, 41, 57, 613098, tzinfo=tzutc()), 'msg_id': '4a08f60f01d0451b81be92408c12a167', 'msg_type': 'execute_request', 'session': 'b88ae4e95f474be1876d1446f51eb304', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '4a08f60f01d0451b81be92408c12a167', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#Linear SVM \\nparameters = {'svm_tfidf__ngram_ran...est_score_\\ngs_clf.best_params_\\ngs_clf.cv_results_\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-24-ffd071b0f211>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1021cf60, execution_c...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000000001C13E4B0, file \"<ipython-input-24-ffd071b0f211>\", line 9>\n        result = <ExecutionResult object at 1021cf60, execution_c...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000000001C13E4B0, file \"<ipython-input-24-ffd071b0f211>\", line 9>, result=<ExecutionResult object at 1021cf60, execution_c...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000000001C13E4B0, file \"<ipython-input-24-ffd071b0f211>\", line 9>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport csv\\nimport numpy as n...okenize import word_tokenize\\nimport seaborn as sb', \"test_filename = 'test.csv'\\ntrain_filename = 'tra...machinelearning\\\\csvfiles\\\\liar_dataset\\\\valid.csv')\", 'def data_obs():\\n    print(\"training dataset size...turn [porter.stem(word) for word in text.split()]', '#show the distribution of labels in the train an... in data_TrainNews.iterrows():\\n    print(row)\\n\"\"\"', 'import pandas as pd\\nimport numpy as np\\nfrom skle...enize\\nfrom gensim.models.word2vec import Word2Vec', \"countV = CountVectorizer()\\ntrain_count = countV....ement'].values)\\n\\nprint(countV)\\nprint(train_count)\", 'def get_countVectorizer_stats():\\n    \\n    #vocab... names\\n    print(countV.get_feature_names()[:25])', '#tf-idf \\ntfidfV = TfidfTransformer()\\ntrain_tfidf...data feature names \\n    print(train_tfidf.A[:10])', \"tfidf_ngram = TfidfVectorizer(stop_words='english',ngram_range=(1,4),use_idf=True,smooth_idf=True)\", \"#bag of words - with n-grams\\ncountV_ngram = Coun...',ngram_range=(1,4),use_idf=True,smooth_idf=True)\", 'def features(sentence, index):\\n    \"\"\" sentence:...ex][1:].lower() != sentence[index][1:]\\n    }\\n    ', 'def untag(tagged_sentence):\\n    return [w for w, t in tagged_sentence]', \"#POS Tagging\\ntagged_sentences = nltk.corpus.tree...train_news['Statement']\\nprint(training_sentences)\", '#Using Word2Vec \\nimport numpy as np\\ndef loadGlov... line.split()[1:]))\\n           for line in lines}', 'class MeanEmbeddingVectorizer(object):\\n    def _...               for words in X\\n            ])\\n\\n\"\"\"', 'import numpy as np\\nimport pandas as pd\\nimport pi...om sklearn.metrics import average_precision_score', \"#string to test\\ndoc_new = ['obama is running for president in 2016']\", '#Using bag of words\\n#building classifier using n...d_pipeline)\\nbuild_confusion_matrix(random_forest)', '##Now using n-grams\\n#naive-bayes classifier\\nnb_p...gram)\\nbuild_confusion_matrix(random_forest_ngram)', ...], 'KFold': <class 'sklearn.cross_validation.KFold'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MeanEmbeddingVectorizer': <class '__main__.MeanEmbeddingVectorizer'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {4: '#converting multiclass labels present in our dat...row in data_TrainNews.iterrows():\\n    print(row)\\n', 15: '\\nclass TfidfEmbeddingVectorizer(object):\\n    def...)\\n                for words in X\\n            ])\\n\\n', 18: (None, None, None, None, None), 22: {'mean_fit_time': array([1.02366885e+00, 1.31106...075e-03,\n       1.99449338e-03, 2.11728018e-03])}, 23: {'mean_fit_time': array([0.28060047, 1.39943592,...0.00184089, 0.00412382, 0.00162906, 0.00412382])}}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'PorterStemmer': <class 'nltk.stem.porter.PorterStemmer'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport csv\\nimport numpy as n...okenize import word_tokenize\\nimport seaborn as sb', \"test_filename = 'test.csv'\\ntrain_filename = 'tra...machinelearning\\\\csvfiles\\\\liar_dataset\\\\valid.csv')\", 'def data_obs():\\n    print(\"training dataset size...turn [porter.stem(word) for word in text.split()]', '#show the distribution of labels in the train an... in data_TrainNews.iterrows():\\n    print(row)\\n\"\"\"', 'import pandas as pd\\nimport numpy as np\\nfrom skle...enize\\nfrom gensim.models.word2vec import Word2Vec', \"countV = CountVectorizer()\\ntrain_count = countV....ement'].values)\\n\\nprint(countV)\\nprint(train_count)\", 'def get_countVectorizer_stats():\\n    \\n    #vocab... names\\n    print(countV.get_feature_names()[:25])', '#tf-idf \\ntfidfV = TfidfTransformer()\\ntrain_tfidf...data feature names \\n    print(train_tfidf.A[:10])', \"tfidf_ngram = TfidfVectorizer(stop_words='english',ngram_range=(1,4),use_idf=True,smooth_idf=True)\", \"#bag of words - with n-grams\\ncountV_ngram = Coun...',ngram_range=(1,4),use_idf=True,smooth_idf=True)\", 'def features(sentence, index):\\n    \"\"\" sentence:...ex][1:].lower() != sentence[index][1:]\\n    }\\n    ', 'def untag(tagged_sentence):\\n    return [w for w, t in tagged_sentence]', \"#POS Tagging\\ntagged_sentences = nltk.corpus.tree...train_news['Statement']\\nprint(training_sentences)\", '#Using Word2Vec \\nimport numpy as np\\ndef loadGlov... line.split()[1:]))\\n           for line in lines}', 'class MeanEmbeddingVectorizer(object):\\n    def _...               for words in X\\n            ])\\n\\n\"\"\"', 'import numpy as np\\nimport pandas as pd\\nimport pi...om sklearn.metrics import average_precision_score', \"#string to test\\ndoc_new = ['obama is running for president in 2016']\", '#Using bag of words\\n#building classifier using n...d_pipeline)\\nbuild_confusion_matrix(random_forest)', '##Now using n-grams\\n#naive-bayes classifier\\nnb_p...gram)\\nbuild_confusion_matrix(random_forest_ngram)', ...], 'KFold': <class 'sklearn.cross_validation.KFold'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MeanEmbeddingVectorizer': <class '__main__.MeanEmbeddingVectorizer'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {4: '#converting multiclass labels present in our dat...row in data_TrainNews.iterrows():\\n    print(row)\\n', 15: '\\nclass TfidfEmbeddingVectorizer(object):\\n    def...)\\n                for words in X\\n            ])\\n\\n', 18: (None, None, None, None, None), 22: {'mean_fit_time': array([1.02366885e+00, 1.31106...075e-03,\n       1.99449338e-03, 2.11728018e-03])}, 23: {'mean_fit_time': array([0.28060047, 1.39943592,...0.00184089, 0.00412382, 0.00162906, 0.00412382])}}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'PorterStemmer': <class 'nltk.stem.porter.PorterStemmer'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\PB\\<ipython-input-24-ffd071b0f211> in <module>()\n      4                'svm_tfidf__smooth_idf': (True, False),\n      5                'svm_clf__penalty': ('l1','l2'),\n      6 }\n      7 \n      8 gs_clf = GridSearchCV(svm_pipeline_ngram, parameters, n_jobs=-1)\n----> 9 gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n     10 \n     11 gs_clf.best_score_\n     12 gs_clf.best_params_\n     13 gs_clf.cv_results_\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=0), X=0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, y=0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = 0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object\n        y = 0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Nov 13 22:42:06 2018\nPID: 1820                    Python 3.6.5: C:\\Users\\PB\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), 0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, 0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, {'score': <function _passthrough_scorer>}, array([3282, 3283, 3285, ..., 9997, 9998, 9999]), array([   0,    1,    2, ..., 3369, 3371, 3372]), 0, {'svm_clf__penalty': 'l1', 'svm_tfidf__ngram_range': (1, 1), 'svm_tfidf__smooth_idf': True, 'svm_tfidf__use_idf': True}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), 0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, 0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, {'score': <function _passthrough_scorer>}, array([3282, 3283, 3285, ..., 9997, 9998, 9999]), array([   0,    1,    2, ..., 3369, 3371, 3372]), 0, {'svm_clf__penalty': 'l1', 'svm_tfidf__ngram_range': (1, 1), 'svm_tfidf__smooth_idf': True, 'svm_tfidf__use_idf': True})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), X=0       Says the Annies List political group sup...le.\nName: Statement, Length: 10000, dtype: object, y=0       False\n1        True\n2        True\n3     ...     True\nName: Label, Length: 10000, dtype: bool, scorer={'score': <function _passthrough_scorer>}, train=array([3282, 3283, 3285, ..., 9997, 9998, 9999]), test=array([   0,    1,    2, ..., 3369, 3371, 3372]), verbose=0, parameters={'svm_clf__penalty': 'l1', 'svm_tfidf__ngram_range': (1, 1), 'svm_tfidf__smooth_idf': True, 'svm_tfidf__use_idf': True}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...andom_state=None, tol=0.0001,\n     verbose=0))])>\n        X_train = 3282    Without Westside MAX, wed need to add 2....ple.\nName: Statement, Length: 6666, dtype: object\n        y_train = 3282    False\n3283    False\n3285    False\n3286  ...9     True\nName: Label, Length: 6666, dtype: bool\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('svm_tfidf', ...random_state=None, tol=0.0001,\n     verbose=0))]), X=3282    Without Westside MAX, wed need to add 2....ple.\nName: Statement, Length: 6666, dtype: object, y=3282    False\n3283    False\n3285    False\n3286  ...9     True\nName: Label, Length: 6666, dtype: bool, **fit_params={})\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n    248         Xt, fit_params = self._fit(X, y, **fit_params)\n    249         if self._final_estimator is not None:\n--> 250             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method LinearSVC.fit of LinearSVC(C=1.0, ..., random_state=None, tol=0.0001,\n     verbose=0)>\n        Xt = <6666x9715 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = 3282    False\n3283    False\n3285    False\n3286  ...9     True\nName: Label, Length: 6666, dtype: bool\n        fit_params = {}\n    251         return self\n    252 \n    253     def fit_transform(self, X, y=None, **fit_params):\n    254         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\classes.py in fit(self=LinearSVC(C=1.0, class_weight=None, dual=True, f...', random_state=None, tol=0.0001,\n     verbose=0), X=<6666x9715 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ...,  True, False,  True]), sample_weight=None)\n    230 \n    231         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n    232             X, y, self.C, self.fit_intercept, self.intercept_scaling,\n    233             self.class_weight, self.penalty, self.dual, self.verbose,\n    234             self.max_iter, self.tol, self.random_state, self.multi_class,\n--> 235             self.loss, sample_weight=sample_weight)\n        self.loss = 'squared_hinge'\n        sample_weight = None\n    236 \n    237         if self.multi_class == \"crammer_singer\" and len(self.classes_) == 2:\n    238             self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)\n    239             if self.fit_intercept:\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py in _fit_liblinear(X=<6666x9715 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ...,  True, False,  True]), C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, penalty='l1', dual=True, verbose=0, max_iter=1000, tol=0.0001, random_state=None, multi_class='ovr', loss='squared_hinge', epsilon=0.1, sample_weight=array([1., 1., 1., ..., 1., 1., 1.]))\n    881         sample_weight = np.ones(X.shape[0])\n    882     else:\n    883         sample_weight = np.array(sample_weight, dtype=np.float64, order='C')\n    884         check_consistent_length(sample_weight, X)\n    885 \n--> 886     solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n        solver_type = undefined\n        multi_class = 'ovr'\n        penalty = 'l1'\n        loss = 'squared_hinge'\n        dual = True\n    887     raw_coef_, n_iter_ = liblinear.train_wrap(\n    888         X, y_ind, sp.isspmatrix(X), solver_type, tol, bias, C,\n    889         class_weight_, max_iter, rnd.randint(np.iinfo('i').max),\n    890         epsilon, sample_weight)\n\n...........................................................................\nC:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py in _get_liblinear_solver_type(multi_class='ovr', penalty='l1', loss='squared_hinge', dual=True)\n    742                                 % (penalty, loss, dual))\n    743             else:\n    744                 return solver_num\n    745     raise ValueError('Unsupported set of arguments: %s, '\n    746                      'Parameters: penalty=%r, loss=%r, dual=%r'\n--> 747                      % (error_string, penalty, loss, dual))\n        error_string = \"The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True\"\n        penalty = 'l1'\n        loss = 'squared_hinge'\n        dual = True\n    748 \n    749 \n    750 def _fit_liblinear(X, y, C, fit_intercept, intercept_scaling, class_weight,\n    751                    penalty, dual, verbose, max_iter, tol,\n\nValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "#Linear SVM \n",
    "parameters = {'svm_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'svm_tfidf__use_idf': (True, False),\n",
    "               'svm_tfidf__smooth_idf': (True, False),\n",
    "               'svm_clf__penalty': ('l1','l2'),\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(svm_pipeline_ngram, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.33      0.00      0.00      1169\n",
      "       True       0.54      1.00      0.70      1382\n",
      "\n",
      "avg / total       0.45      0.54      0.38      2551\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.64      0.38      0.48      1169\n",
      "       True       0.61      0.82      0.70      1382\n",
      "\n",
      "avg / total       0.62      0.62      0.60      2551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "random_forest_final = Pipeline([\n",
    "        ('rf_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,3),use_idf=True,smooth_idf=True)),\n",
    "        ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3,max_depth=10))\n",
    "        ])\n",
    "    \n",
    "random_forest_final.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_rf_final = random_forest_final.predict(test_news['Statement'])\n",
    "np.mean(predicted_rf_final == test_news['Label'])\n",
    "print(metrics.classification_report(test_news['Label'], predicted_rf_final))\n",
    "\n",
    "logR_pipeline_final = Pipeline([\n",
    "        #('LogRCV',countV_ngram),\n",
    "        ('LogR_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,5),use_idf=True,smooth_idf=False)),\n",
    "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
    "        ])\n",
    "\n",
    "logR_pipeline_final.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_LogR_final = logR_pipeline_final.predict(test_news['Statement'])\n",
    "np.mean(predicted_LogR_final == test_news['Label'])\n",
    "#accuracy = 0.62\n",
    "print(metrics.classification_report(test_news['Label'], predicted_LogR_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving best model to the disk\n",
    "model_file = 'final_model.sav'\n",
    "pickle.dump(logR_pipeline_ngram,open(model_file,'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting learing curve\n",
    "def plot_learing_curve(pipeline,title):\n",
    "    size = 10000\n",
    "    cv = KFold(size, shuffle=True)\n",
    "    \n",
    "    X = train_news[\"Statement\"]\n",
    "    y = train_news[\"Label\"]\n",
    "    \n",
    "    pl = pipeline\n",
    "    pl.fit(X,y)\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(pl, X, y, n_jobs=-1, cv=cv, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "       \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "     \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # box-like grid\n",
    "    plt.grid()\n",
    "    \n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcHWWd7/HPt7cs3WERJCxJCAwRDaCCLYyi1+aCDDheGWcYDRMUHTVuqDMuow53UBkZhRFc7uBoxo2RSEDcIoIISKsoOgEFwhaJQEgT9iWhu5NOd5/f/aPqVNc5fXpJ6OruE77v16tep+qpp6p+z0nn+VU9dU4dRQRmZmYADVMdgJmZTR9OCmZmlnFSMDOzjJOCmZllnBTMzCzjpGBmZhknBZsWJP2zpK8VsN8OSV0Tvd/JJCkkHVTQvpdK+llu+WhJd0vqlvRXkq6UdFoRx7bpSf6egk0ESfcBs4ADI6InLXs7cGpEdExhXB3ARRExb6piGIukfYBPA68B2oAHgEuAcyOiR1IAiyJi3STEci2wKiK+WPSxbHrylYJNpCbgA1MdRD2R9BzgBpKE+rKImAO8GtgN+LMpCGl/4PZnuhNJTRMQi00BJwWbSP8OfFjSbrVWSvqipA2SNku6SdIrc+s+KemidP6nkk6v2vYWSX+dzj9f0tWSnpC0VtIbxgosHZ56TNJ9kpbmyv9S0h/SmDZI+mRu3U8kva9qP7dK+qux4pD0Gkl3SHpa0gOSPjxCaB8Enia5oroPICI2RMQHIuLWGu0YLd6Zki6S9LikpyStljQ3XfcWSfek8dxbfg/S8uvT+T8BBwI/ToePZkjqTK/4ysf4e0l3SnpS0lWS9s+tC0nvlXQ3cPcY/yQ2TTkp2ES6EegERuoAVwMvBp4DfAf4rqSZNep9BzilvCBpMckZ7E8ktQJXp3X2Sut9WdIho8S1N7AnsB9wGrBc0sHpuh7gzSRn5n8JvLvc6QMXAqfm4nhRuo8rxhHH14F3pmf+hwI/HyG244DvR0RplPjzRov3NGBXYD6wB/AuYEsa65eAE9N4Xg7cXL3jiPgz4H7g/0REW0T05denx/ln4K+B5wK/Ai6u2s1fAUcBi8fZHptmnBRsop0JvE/Sc6tXRMRFEfF4RAxExHnADODgYXuAHwAvzp2FLiXpOPuA1wL3RcQ30/38HvgecPIYcf1LRPRFxC+AnwBvSGPqjIg1EVFKz8wvBl6VbvMjYJGkRenym4BLImLbOOLoBxZL2iUinkzX17IH8OAYsWfGiLc/3d9BETEYETdFxOZ0XQk4VNKsiHgwInZkiOidwGci4s6IGAD+jcp/J9L1T0TElh3Yv00DTgo2oSLiNuBy4GPV6yR9KB162CTpKZKz2j1r7ONpko57SVq0BFiRzu8PHJUOjzyV7mcpsLekBemwR7ek7twunyzf/E6tB/ZNYzpK0nWSHpW0ieTses80jj7gUuBUSQ0kVwPfHiuOdP3fkNw4Xi/pF5JeNsJb9jiwzwjrhhkt3jS2q4CVkjZKOldSc9r2N6Z1H0yHxZ4/3mPm7A98MdfeJwCRXD2VbdiB/do04qRgRfgE8A5ynUV6/+CjJGfou0fEbsAmkk6llouBU9LOdBZwXVq+AfhFROyWm9oi4t0RcX863xYRbbl97Z4OoZQtADam898BVgHzI2JX4CtVMV1I0tkfC/RGxA1jxQEQEasj4iSSoaUfkiSXWq4BXp8mnfEYMd6I6I+IT0XEYpIhoteSDDUREVdFxKtJEtBdwH+N83h5G0iGxPJtnhURv8nV8ccZ65yTgk249KOTlwDvzxXPAQaAR4EmSWcCu4yymytIzkzPIhmyKY+5Xw48T9KbJDWn00slvWCMsD4lqSVNTq8FvpuL64mI2CrpSODvqtpyA8nQy3kMXSWMGkd6nKWSdo2IfmAzMDhCXOen78OF5WEYSftJOl/SC2vUHzFeScdIOkxSY3rMfmBQ0lxJr0sTYx/QPUo8o/kK8PHyfRNJu0r62x3Yj01jTgpWlLOA/Nn5VcCVwB9Jhm+2MspQQzp0832SG7HfyZU/DRxPMqS0EXgIOIfk/sRIHgKeTOuvAN4VEXel694DnCXpaZL7IbXO6P8bOAy4aDvieBNwn6TNJMM2p1JDRDxBclbfD/wujeNakquoWt9LGC3evYHLSBLCncAv0pgbgA+lcT5Bcg/iPbXiGU1E/CBt48q0XbcBJ27vfmx685fXzMYg6c3Asoh4xVTHYlY0XymYjULSbJKz6uVTHYvZZHBSMBuBpL8guQfyMLkhLLOdmYePzMws4ysFMzPL1N1Dq/bcc89YuHDhlB2/p6eH1tbWsSvWAbdl+tlZ2gFuy3Rz0003PRYRw540UK3uksLChQu58cYbp+z4nZ2ddHR0TNnxJ5LbMv3sLO0At2W6kbR+PPU8fGRmZhknBTMzyzgpmJlZpu7uKZiZPdv19/fT1dXF1q1bh62bOXMm8+bNo7m5eYf27aRgZlZnurq6mDNnDgsXLkQaeqhvRPD444/T1dXFAQccsEP79vCRmVmd2bp1K3vssUdFQgCQxB577FHzCmK8nBTMzOpQdUIYq3y8nBTMzCzjpGBmZhknBTOzOjTSw0yf6UNOnRTMzOrMzJkzefzxx4clgPKnj2bOnLnD+/ZHUs3M6sy8efPo6uri0UcfHbau/D2FHeWkYGZWZ5qbm3f4ewhjKWz4SNI3JD0i6bYR1kvSlyStk3SrpCOKisXMzManyHsK3wJOGGX9icCidFoG/GeBsZiZ2TgUlhQi4pfAE6NUOQn470j8FthN0j6FBLNiBSxcCA0NyeuKFYUcxsys3hX6G82SFgKXR8ShNdZdDnw2Iq5Pl68FPhoRw35BR9IykqsJ5s6d+5KVK1eOO4a9rrmGgz/3ORr7+rKywRkzWPvhD/PIccdtX4OA7u5u2tratnu76Wiktux1zTUc+LWvMeORR+jbay/uefvbd+i9mkw7y7/LztIOcFumm2OOOeamiGgfq95UJoWfAJ+pSgr/FBE3jbbP9vb22K5fXlu4ENbX+MGh2bPh9a+HxkZoakpeGxqS+fJyecot3/3wwyxasKCyTnmbpqZkH42N0NxcuW11/er5cv3qGPKv+fKGBsh/nb08X6tsBDV/TWrFCli2DHp7K9+r5cth6dLxv++TbGf4ZSzYedoBbst0I2lcSWEqP33UBczPLc8DNk74Ue6/v3Z5by/89KcwOFg5lUpDrzUsmvAAn4F8Eionk5GWq6eGBg4fGEg6/Hz56tWQu6oCkvfqXe+CNWugrS2ZWluH5vPTnDnJ1Nqa7O8ZPofFzCbXVCaFVcDpklYCRwGbIuLBCT/KggW1rxT23Reuuw4iandcEZVJIp1+fe+9HD1vXrI8MJCsL5WG5svbjLVcnYhGq7O9x6jef61jDg4y2N0NLS3Juv5+2Lp1eEIo6+6Gc87Zvvd+5swk6eSn1tahhNLampSVk8lIyaa1dSjZzJmTxDydrFgBZ5yRnIAsWABnnz2tr6rMRlNYUpB0MdAB7CmpC/gE0AwQEV8BrgBeA6wDeoG3FhLI2WfXHg757GfhwAOTzj9vtOUI+ru74Ygjxq5bY9tR61ZfmYy2HFG5/fZsm1u+9a676Hje8yrXvfzlsLHGBdu++8I11yTv45YtydTbOzTVWi6XbdkCPT1Dy48/Pnyb7RnGbG5O/g1nzcoSy4sB9tqrMuHkE0p1ebmsnIx22SVJYtt7ZVM93LZ+fbIMTgxWlwpLChFxyhjrA3hvUcfPlP9jTtSZnJR0HjuDP/0J9t+/suzcc2sn0XPPhYMPHkpII02l0tDrSFP+6qe83Nc3dpIZbd0TT8BDDw1PSP39438/GhqGkk35qqZ8JVMr2bS2wnnnVb5XkCx/5CNw5JFDV0izZsGMGR5Os2nv2fGN5qVLfdY2XhOdRMdrtAQz0rpcgrn5llvoWLy4MtlEJENi5auUnp7aVzr5+fwVTT7hPPBAZd2xfsTkwQeh+iqsfEJRPc2alb0e0tcHe++dlJWTU259RdIqz+fr5qdZs5JENx15yG3aenYkBds+U5FEpWd2Ft3cDPvtN/L60RLMjlzl9PcnCeSEE+Dhh4cfb/fd4aMfHbpPs2VLMl+e+vqSqTy/dSts3szsp59OhqC2bBkq356rnWotLWMmoprT7NlD94Sqy6uXy1dUs2cnH26A0f8tPeS2/SYxiTop2LNDUWfM551Xe7jt85+HJUvGvtKpmlbfdhsdz39+5dVOf3/tpFKdXPLl1fO1tnvyyeSKpjo5PYOfcqS5ORkmmzmToxobk3s21cno+uuT9uSVP+H2619XfoKuPElD8/l1+fLq+tX7yNcvfzJutPnc8u533pm8LyPtq1YM2xPraOWXXQbvf//Qe1ZwEnVSMHsmJnq4be1amD+/9rrqxAJDiaPW+jES0LCpXHdwELZtG19yqTWfTpsefZRZzc1D63t6kg8ZVCeEsu5uuPDCypjz81PoRVN69Bp6e5O/OScFs2losobbnukQ2/YYa6htrOQTwV0338zehxwytL489Hb00SN/wu2662rHIg0/TvV89fLgYLL9eOpWz1e9/v6BBzhi771H30/1drXiqXVPbKz9jPRR8JG+g/UMOSmY2XATkYCammCfGo8zG+0TbtU353f0iQsTvN3mX/0KXvnKSTtehYsvrp0AFizYsWOOwUnBzCbX9gy57WhiKuKKqrFx4vc5Hv/2b7WT6NlnF3I4JwUzm3z+mPj4TfLHxJ0UzMymu0lMotP0my1mZjYVnBTMzCzjpGBmZhknBTMzyzgpmJlZxknBzMwyTgpmZpZxUjAzs4yTgpmZZZwUzMws46RgZmYZJwUzM8s4KZiZWcZJwczMMk4KZmaWcVIwM7OMk4KZmWWcFMzMLOOkYGZmmUKTgqQTJK2VtE7Sx2qsXyDpOkl/kHSrpNcUGY+ZmY2usKQgqRG4ADgRWAycImlxVbX/C1waEYcDS4AvFxWPmZmNrcgrhSOBdRFxT0RsA1YCJ1XVCWCXdH5XYGOB8ZiZ2RgUEcXsWDoZOCEi3p4uvwk4KiJOz9XZB/gZsDvQChwXETfV2NcyYBnA3LlzX7Jy5cpCYh6P7u5u2trapuz4E8ltmX52lnaA2zLdHHPMMTdFRPtY9ZoKjEE1yqoz0CnAtyLiPEkvA74t6dCIKFVsFLEcWA7Q3t4eHR0dRcQ7Lp2dnUzl8SeS2zL97CztALelXhU5fNQFzM8tz2P48NDbgEsBIuIGYCawZ4ExmZnZKIpMCquBRZIOkNRCciN5VVWd+4FjASS9gCQpPFpgTGZmNorCkkJEDACnA1cBd5J8yuh2SWdJel1a7UPAOyTdAlwMvCWKuslhZmZjKvKeAhFxBXBFVdmZufk7gKOLjMHMzMbP32g2M7OMk4KZmWWcFMzMLOOkYGZmGScFMzPLOCmYmVnGScHMzDJOCmZmlnFSMDOzjJOCmZllnBTMzCzjpGBmZhknBTMzyzgpmJlZxknBzMwyTgpmZpZxUjAzs4yTgpmZZZwUzMws46RgZmYZJwUzM8s4KZiZWcZJwczMMk4KZmaWcVIwM7OMk4KZ2TS3Ys0KFn5hIQ2famDhFxayYs2Kwo7lpGBmk24yO7npKCKyqRSlbBosDWbTQGmAgdIA377l2yz78TLWb1pPEKzftJ5lP15W2HvWVMheU5JOAL4INAJfi4jP1qjzBuCTQAC3RMTfFRmT2URbsWYFZ1x7Bvdvup8Fuy7g7GPPZulhS6c6rGkhIpJXIlv+zprv8K6fvIve/l6ArJMbKA2w5JAlQ9uSdJqDMcjA4ACDkXaWMZB1muWOtFxWrlOe7y/1UyqVhs0PlIbqD5Ry+y7vs6rOhgc28Jtf/WZYncHSYEUMWcceg5RKpaGyGGRwMC0vL8fQthXb5RJEKUrc/NDNbCttq3hfe/t7OePaMwr5OyssKUhqBC4AXg10AaslrYqIO3J1FgEfB46OiCcl7VVUPDZ+7uTGb8WaFSz78bJhHRww7vesfLY4GINsHdzK5r7NFWeK5U4rWx4coL/Uz0ApeS3X7R9MygZiqF42X95PaTDbttyRlfdXXld97P5Sf9Yx5zvk/D7z5eXOsufpHprubBo6840BSqUSGzZvYDAGK96D3v5e3vrDt/Luy99d0VmWk8m0sG7sKg1qoFGNyWtD47D5RjXS0NCwXfPVCaHs/k33T3ADE0VeKRwJrIuIewAkrQROAu7I1XkHcEFEPAkQEY8UGI+Nw0R0crWUzxgrymr8hy9fUpc7o4HSANsGt1V0UOX5rHxwgDWb1jB4z2BFZ1nusMr1yp3mYGmQbaVtFR1beX9ZB1u1n6yTrSq7/v7r6Rvsq2hDb38vb/nhW/jEdZ+o6MzzZ6YDpYHsTHKgNFD5Jly/w2/zhGhUI40NjTQ1NGXzjUqWG9RAU0NTsq7c0eXqlstbmlqgCXZt3XWojpJ19226r+Zxg+DUF56a1W9QQ9bJljvKrNNtaKCByo633JFWdMy5DrZi2+p1VG5f7sgblBzngTseYOGhC2lsaERS9l40NjQiRJOSZUmgXJsiUK4giKTOCOtrbXvMhcewsXvjsPdrwa4LdvjfeDRFJoX9gA255S7gqKo6zwOQ9GuSIaZPRsRPq3ckaRmwDGDu3Ll0dnYWEe+4dHd3T+nxd1S+Ay5fkj+26TEuvvJiegZ76B3opWegh3PWnkPvQG/Ftr39vSz70TK+99vvJZ1aekk8EAPZZXB5vhSloTPb3KXzQAwwSO7ynqpL9dy+SpR2rJE3P5N3CBpIOrxGhjq76vly51euW50QygZKA8xrnDfU+TDUueU7qOp1DEBzS3Nl3dz6/Haj7afmdvkzVyrr5OPMOi3VbBqjnrzntunr7WPG7Blp8dCKG+67gUf6hp//7TVjL06efXLV7qqCKC+Wql5r1R0WWu3Od6y6JUrsUtqFvntq/1uPepxxHGusfb113lv53B8/R19p6PgzGmZw6j6nFtIXFZkUar0V1X9OTcAioAOYB/xK0qER8VTFRhHLgeUA7e3t0dHRMeHBjldnZydFHD8isjHUUpRqzg+WBnl629Ns2rqJzX2bearvKTb3bc6mp/ueTqZtT9O9rTuZ+pPXnm099GzrSeb7e9gysGW74usd7OXqx64eOktUI82NzRWvTY1N2foZDTOyM8jy2WNTQ1N2tpg/02xuaK44G6115pmvV7HPdH+P3fcY8w6aVxFfOZ5yjA000NzQTEtTS3I229BCc2MzTWpK2pCeGQLZ2aIkhLLl/DqAQ758CBs2bxj2fs3fZT5XLruyoix/hlhRnvuv8pvrf8PLX/HyUetXb7O9xyhym7yR/q+cv9f5FVejALObZ3P+X57P8YcdP+Z+p0JR/+/Ho4MOXrDmBZM2pFtkUugC5ueW5wHV10BdwG8joh+4V9JakiSxeiIDKWKMvNyJl6JUcz4bJy4NsmVgC5u2bmJTXzJt7tvM5q2b2bxtM9193Wzu21zZeff3ZJ16z7aeinXjGWNtbmhmzow5tLW00dbSxpyWOcxtm8ucljnZcmtLKz0P9XDgQQcyu3k2bc1tzG6ezelXnM4jvcPP4vadsy/Xvfm6oVQfDJ8vh5abL1/mQ9KRVHe0Y3W6+fly3XKHlJ+/ofsGjj7s6IrycqdWPT+RPnPcZ2p2cJ857jPMap613fsTYkbTjIkMcdop/9/zfavxW3rY0kl7f4pMCquBRZIOAB4AlgDVnyz6IXAK8C1Je5IMJ90zkUGMNEY+MDjAGw9947AOvXznf+vA1uwMvHxmvrlvM3c/fDe//uWvk467LzkTz5+BZ2fo6XLPth76S/1jximUdeTlTnu3mbsxb5d5FZ37nBlzsk68taWV2S2zaW1upbU5mW9rbqO5obmyw04OULHc0NDAPX+4h4MXH1wxVnzWMWfxj1f9Y8WVxKymWXz6mE+zYLcFI3a0k9EBj0aIlsaWSTtemTu4HTOZnZxtn8KSQkQMSDoduIrkfsE3IuJ2SWcBN0bEqnTd8ZLuAAaBj0TE4xMZxxnXnlFxFgfJGPl7rngP37/z+8OHV9JOftThlbuGZmc3z67otNta2thz9p4Vy20z0o6+uZXWlmQqn5m3tiQd+symmclVwAideH65qaGp4mZX9Wv55lf5TLxBDcOWAboau9h/t/0rmvbO9nfSNqPNndx2cAdnO5NCv6cQEVcAV1SVnZmbD+CD6VSIkT621dvfyy0P30JrSytzWuawd9ve2Rn6nJY5tM2o7OjbWtqY3TSbR+5+hEMPPzTryBsbGrOrjbRNyZmyGLZc/iRDeey6Vqc+UieeXy6aOzmzZ69Ck8J0sGDXBazftH5Y+b5z9uWaN19DKUoV4+PlTrz80bHycvnjandvvJv9d92/Zqc+2pl5fvzbzGy6GndSkPQKYFFEfFPSc4G2iLi3uNAmxtnHnj3sRuCspln8yyv/hT1m7bFdwy0A6xvXs98u+01FU8zMCjeupCDpE0A7cDDwTaAZuAg4urjQJoZvBJqZjd94rxReDxwO/B4gIjZKmlNYVBPMY+RmZuMz3qekbktvCgeApNbiQjIzs6ky3qRwqaSvArtJegdwDfBfxYVlZmZTYVzDRxHxOUmvBjaT3Fc4MyKuLjQyMzObdGMmhfQR2FdFxHGAE4GZ2U5szOGjiBgEeiXtOgnxmJnZFBrvp4+2AmskXQ30lAsj4v2FRGVmZlNivEnhJ+lkZmY7sfHeaL5QUgvpj+IAa9PHXZuZ2U5kvN9o7gAuBO4jeUrQfEmnRcQviwvNzMwm23iHj84Djo+ItQCSngdcDLykqMDMzGzyjffLa83lhAAQEX8kef6RmZntRMZ7pXCjpK8D306XlwI3FROSmZlNlfEmhXcD7wXeT3JP4ZfAl4sKyszMpsZ4k0IT8MWIOB+ybznv3L8ubmb2LDTeewrXArNyy7NIHopnZmY7kfEmhZkR0V1eSOdnFxOSmZlNlfEmhR5JR5QXJLUDW4oJyczMpsp47yn8A/BdSRtJfmhnX+CNhUVlZmZTYtQrBUkvlbR3RKwGng9cAgwAPwXunYT4zMxsEo01fPRVYFs6/zLgn4ELgCeB5QXGZWZmU2Cs4aPGiHginX8jsDwivgd8T9LNxYZmZmaTbawrhUZJ5cRxLPDz3Lrx3o8wM7M6MVbHfjHwC0mPkXza6FcAkg4CNhUcm5mZTbJRrxQi4mzgQ8C3gFdEROS2e99YO5d0gqS1ktZJ+tgo9U6WFOlHXc3MbIqMOQQUEb+tUfbHsbZLH4VxAfBqoAtYLWlVRNxRVW8OyTOVfjfeoM3MrBjj/fLajjgSWBcR90TENmAlcFKNev8KnEvyO9BmZjaFirxZvB+wIbfcBRyVryDpcGB+RFwu6cMj7UjSMmAZwNy5c+ns7Jz4aMepu7t7So8/kdyW6WdnaQe4LfWqyKSgGmWRrZQagM8DbxlrRxGxnPR7Ee3t7dHR0TExEe6Azs5OpvL4E8ltmX52lnaA21Kvihw+6gLm55bnARtzy3OAQ4FOSfcBfw6s8s1mM7OpU2RSWA0sknSApBZgCbCqvDIiNkXEnhGxMCIWAr8FXhcRNxYYk5mZjaKwpBARA8DpwFXAncClEXG7pLMkva6o45qZ2Y4r9FvJEXEFcEVV2Zkj1O0oMhYzMxtbkcNHZmZWZ5wUzMws46RgZmYZJwUzM8s4KZiZWcZJwczMMk4KZmaWcVIwM7OMk4KZmWWcFMzMLOOkYGZmGScFMzPLOCmYmVnGScHMzDJOCmZmlnFSMDOzjJOCmZllnBTMzCzjpGBmZhknBTMzyzgpmJlZxknBzMwyTgpmZpZxUjAzs4yTgpmZZZwUzMws46RgZmaZQpOCpBMkrZW0TtLHaqz/oKQ7JN0q6VpJ+xcZj5mZja6wpCCpEbgAOBFYDJwiaXFVtT8A7RHxQuAy4Nyi4jEzs7EVeaVwJLAuIu6JiG3ASuCkfIWIuC4ietPF3wLzCozHzMzGoIgoZsfSycAJEfH2dPlNwFERcfoI9f8DeCgiPl1j3TJgGcDcuXNfsnLlykJiHo/u7m7a2tqm7PgTyW2ZfnaWdoDbMt0cc8wxN0VE+1j1mgqMQTXKamYgSacC7cCraq2PiOXAcoD29vbo6OiYoBC3X2dnJ1N5/Inktkw/O0s7wG2pV0UmhS5gfm55HrCxupKk44AzgFdFRF+B8ZiZ2RiKvKewGlgk6QBJLcASYFW+gqTDga8Cr4uIRwqMxczMxqGwpBARA8DpwFXAncClEXG7pLMkvS6t9u9AG/BdSTdLWjXC7szMbBIUOXxERFwBXFFVdmZu/rgij29mZtvH32g2M7OMk4KZmWWcFMzMLOOkYGZmGScFMzPLOCmYmVnGScHMzDJOCmZmlnFSMDOzjJOCmZllnBTMzCzjpGBmZhknBTMzyzgpmJlZxknBzMwyTgpmZpZxUjAzs4yTgpmZZZwUzMws46RgZmYZJwUzM8s4KZiZWcZJwczMMk4KZmaWcVIwM7OMk4KZmWWcFMzMLOOkYGZmmUKTgqQTJK2VtE7Sx2qsnyHpknT97yQtLDIeMzMbXWFJQVIjcAFwIrAYOEXS4qpqbwOejIiDgM8D5xQVj5mZja3IK4UjgXURcU9EbANWAidV1TkJuDCdvww4VpIKjMnMzEbRVOC+9wM25Ja7gKNGqhMRA5I2AXsAj+UrSVoGLAOYO3cunZ2dBYU8tu7u7ik9/kRyW6afnaUd4LbUqyKTQq0z/tiBOkTEcmA5QHt7e3R0dDzj4HZUZ2cnU3n8ieS2TD87SzvAbalXRQ4fdQHzc8vzgI0j1ZHUBOwKPFFgTGZmNooik8JqYJGkAyS1AEuAVVV1VgGnpfMnAz+PiGFXCmZmNjkKGz5K7xGcDlwFNALfiIjbJZ0F3BgRq4CvA9+WtI7kCmFJUfGYmdnYirynQERcAVxRVXZmbn4r8LdFxmBmZuPnbzSbmVnGScHMzDJOCmZmlnFSMDOzjJOCmZllnBTMzCzjpGBmZhknBTMzyzgpmJlZxknBzMwyTgpmZpZxUjAzs4zq7UnVkh4F1k9hCHtS9ctwdcxtmX52lnaA2zLd7B8Rzx2rUt0lhakm6caIaJ+GBBf9AAAH6ElEQVTqOCaC2zL97CztALelXnn4yMzMMk4KZmaWcVLYfsunOoAJ5LZMPztLO8BtqUu+p2BmZhlfKZiZWcZJwczMMk4KgKRvSHpE0m25sudIulrS3enr7mm5JH1J0jpJt0o6IrfNaWn9uyWdNgXtmC/pOkl3Srpd0gfquC0zJf2PpFvStnwqLT9A0u/SuC6R1JKWz0iX16XrF+b29fG0fK2kv5jstqQxNEr6g6TL67wd90laI+lmSTemZXX395XGsJukyyTdlf6feVm9tmVCRcSzfgL+F3AEcFuu7FzgY+n8x4Bz0vnXAFcCAv4c+F1a/hzgnvR193R+90luxz7AEen8HOCPwOI6bYuAtnS+GfhdGuOlwJK0/CvAu9P59wBfSeeXAJek84uBW4AZwAHAn4DGKfgb+yDwHeDydLle23EfsGdVWd39faVxXAi8PZ1vAXar17ZM6Psy1QFMlwlYSGVSWAvsk87vA6xN578KnFJdDzgF+GquvKLeFLXpR8Cr670twGzg98BRJN8qbUrLXwZclc5fBbwsnW9K6wn4OPDx3L6yepMY/zzgWuB/A5encdVdO9Lj3sfwpFB3f1/ALsC9pB+2qee2TPTk4aORzY2IBwHS173S8v2ADbl6XWnZSOVTIh12OJzkDLsu25IOudwMPAJcTXJ2/FREDNSIK4s5Xb8J2IPp0ZYvAP8ElNLlPajPdgAE8DNJN0lalpbV49/XgcCjwDfTYb2vSWqlPtsyoZwUtp9qlMUo5ZNOUhvwPeAfImLzaFVrlE2btkTEYES8mORM+0jgBbWqpa/Tsi2SXgs8EhE35YtrVJ3W7cg5OiKOAE4E3ivpf41Sdzq3pYlkyPg/I+JwoIdkuGgk07ktE8pJYWQPS9oHIH19JC3vAubn6s0DNo5SPqkkNZMkhBUR8f20uC7bUhYRTwGdJGO5u0lqqhFXFnO6flfgCaa+LUcDr5N0H7CSZAjpC9RfOwCIiI3p6yPAD0iSdT3+fXUBXRHxu3T5MpIkUY9tmVBOCiNbBZQ/SXAayfh8ufzN6acR/hzYlF5mXgUcL2n39BMLx6dlk0aSgK8Dd0bE+blV9diW50raLZ2fBRwH3AlcB5ycVqtuS7mNJwM/j2SQdxWwJP1UzwHAIuB/JqcVEBEfj4h5EbGQ5MbxzyNiKXXWDgBJrZLmlOdJ/i5uow7/viLiIWCDpIPTomOBO6jDtky4qb6pMR0m4GLgQaCfJPO/jWQc91rg7vT1OWldAReQjG+vAdpz+/l7YF06vXUK2vEKkkvXW4Gb0+k1ddqWFwJ/SNtyG3BmWn4gSWe4DvguMCMtn5kur0vXH5jb1xlpG9cCJ07h31kHQ58+qrt2pDHfkk63A2ek5XX395XG8GLgxvRv7Icknx6qy7ZM5OTHXJiZWcbDR2ZmlnFSMDOzjJOCmZllnBTMzCzjpGBmZhknBZt2JO2RPoXzZkkPSXogt9wyzn18M/cZ9JHqvFfS0omJenqQdL2kF091HFa//JFUm9YkfRLojojPVZWL5O+3VHPDZylJ1wOnR8TNUx2L1SdfKVjdkHSQpNskfYXkqan7SFou6UYlv7lwZq7u9ZJeLKlJ0lOSPqvktxlukLRXWufTkv4hV/+zSn7DYa2kl6flrZK+l257cXqsYWfikl4q6Rfpg+KulDRXUnO6/Iq0zr9r6HchPiVpdbk9aZIrx3G+pF9JukNSu6QfKHlW/ydz78Ptkr6t5LcNLk2/9V0d04lpe3+v5DcaWnNx3KHkdwHOmdB/JKt7TgpWbxYDX4+IwyPiAZJn37cDLwJeLWlxjW12BX4RES8CbiD5BmotiogjgY8A5QTzPuChdNvPkjx5tnIjaQbwReBvIuIlwEXAv0ZEP/BWYLmk40mee/TpdLMvRsRLgcPS+E7I7XJLRLyS5JElPwTeldZbVn70R/o+XBARhwFbgXdWxbQXyQPejo3kAXa3Ah+QNJfkW+6HRMQLgc+M8F7Ys5STgtWbP0XE6tzyKZJ+T3Ll8AKSzrLaloi4Mp2/ieS3M2r5fo06ryB5kB0RUX68Q7UXAIcA1yh51PfHSB+SFhG3ptv/iOQRCP3pNsdK+h+SR0a8Kt2+bFX6ugZYExEPR8RWkt8ymJeuuzcifpvOX5TGmfdykvfiN2lMS9M2PUHyCO//kvR6kqeDmmWaxq5iNq1knZikRcAHgCMj4ilJF5E8O6jattz8ICP/3ffVqFPr0cjVBNyant3XcijJ7yKUh61mA/9B8it5D0j6dFXc5ThKufnycjmu6puB1csCfhoRbxoWrNRO8uNLS4B3kzzEzQzwlYLVt12Ap4HNSh5zXMTvFl8PvAFA0mHUvhK5A9hP0pFpvRZJh6TzbwTaSB6Gd4GkXYBZJB38Y+lTR/9mB+I6QNJL0/lT0jjzfgO8StKBaRytkhalx9slIi4H/pEaw2H27OYrBatnvyfpkG8j+W3cXxdwjP8H/LekW9Pj3UZy1p+JiD5JJwNfSjvdJuA8SY+S3EPoSK8Ivgp8PiLeJunCdF/rSX4db3vdDrxD0teBu4DlVTE9LOltwCW5j/H+M7AF+H56H6SB5LejzTL+SKrZKJT80E1TRGxNh6t+BiyKoZ/SnIqYDgIui+RX6cwmlK8UzEbXBlybJgcB75zKhGBWNF8pmJlZxjeazcws46RgZmYZJwUzM8s4KZiZWcZJwczMMv8f+RBYYWo2FmsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PB\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-f3bbc29f3413>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplot_learing_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_pipeline_ngram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"SVM Classifier\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplot_learing_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgd_pipeline_ngram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"SGD Classifier\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplot_learing_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_forest_ngram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"RandomForest Classifier\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-f94a1012898d>\u001b[0m in \u001b[0;36mplot_learing_curve\u001b[1;34m(pipeline, title)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtrain_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_learing_curve(logR_pipeline_ngram,\"Naive-bayes Classifier\")\n",
    "plot_learing_curve(nb_pipeline_ngram,\"LogisticRegression Classifier\")\n",
    "plot_learing_curve(svm_pipeline_ngram,\"SVM Classifier\")\n",
    "plot_learing_curve(sgd_pipeline_ngram,\"SGD Classifier\")\n",
    "plot_learing_curve(random_forest_ngram,\"RandomForest Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting Precision-Recall curve\n",
    "def plot_PR_curve(classifier):\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(test_news['Label'], classifier)\n",
    "    average_precision = average_precision_score(test_news['Label'], classifier)\n",
    "    \n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('2-class Random Forest Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "              average_precision))\n",
    "    \n",
    "plot_PR_curve(predicted_LogR_ngram)\n",
    "plot_PR_curve(predicted_rf_ngram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3.3294        percent    -2.0936      obamacare', '1.8487        million    -1.8243          obama', '1.7412        average    -1.6493           says', '1.6576            day    -1.5977      wisconsin', '1.6518        georgia    -1.4068            rep', '1.6176           debt    -1.3506     government', '1.6030      countries    -1.2291           care', '1.5747          times    -1.2012           plan', '1.4223        highest    -1.1894      president', '1.3854        country    -1.1783   scott walker', '1.3493           half    -1.1634         walker', '1.3291            000    -1.0760         obamas', '1.2225       american    -1.0427          scott', '1.2138            cut    -1.0121           away', '1.2061         months    -0.9789        clinton', '1.1685         states    -0.9713         barack', '1.1640      americans    -0.9658       medicare', '1.0665           rate    -0.9371       stimulus', '1.0620           year    -0.9208          white', '1.0164             60    -0.8999          going', '0.9680           weve    -0.8909        illegal', '0.9566         nearly    -0.8548       care law', '0.9470             10    -0.8433       security', '0.9450       spending    -0.8200         social', '0.9358        college    -0.8191          voted', '0.9208         lowest    -0.8115       increase', '0.9156           ohio    -0.8112           know', '0.8974          terms    -0.8112health care law', '0.8928         cities    -0.8077          group', '0.8724          lower    -0.8038         muslim', '0.8527        poverty    -0.7983   barack obama', '0.8449       trillion    -0.7980      democrats', '0.8390         dollar    -0.7874says barack obama', '0.8355        decades    -0.7838    health care', '0.8199         romney    -0.7330           stop', '0.8095             40    -0.7317       benghazi', '0.8074        workers    -0.7256        hillary', '0.8022        members    -0.7197       supports', '0.7908          worth    -0.7190      gov scott', '0.7902      education    -0.7163    raise taxes', '0.7901          today    -0.7157       deciding', '0.7659             50    -0.7094          china', '0.7656          worst    -0.7042            tom', '0.7634         mccain    -0.6920 says president', '0.7540        torture    -0.6900      dont know', '0.7513says donald trump    -0.6852   middle class', '0.7459        elected    -0.6820       says rep', '0.7388        florida    -0.6812    500 billion', '0.7320        funding    -0.6800       illegals', '0.7252           does    -0.6739          wants']\n",
      "['-8.3673           says    -12.4938        00 2014', '-8.4799        percent    -12.493800 2014 provisions', '-8.9058          state    -12.493800 2014 provisions incorporated', '-8.9942            000    -12.4938   000 000 send', '-9.0719          years    -12.4938000 000 send community', '-9.0913           year    -12.4938000 000 support', '-9.1003            tax    -12.4938000 000 support supreme', '-9.1008         states    -12.4938         000 10', '-9.1342        million    -12.4938     000 10 000', '-9.2124         people    -12.4938000 10 000 refugees', '-9.2204          obama    -12.4938     000 20 000', '-9.2820           jobs    -12.4938000 20 000 infrastructural', '-9.3021         health    -12.4938000 20 000 jobs', '-9.3725      president    -12.4938         000 25', '-9.3907          texas    -12.4938     000 25 000', '-9.3952        country    -12.4938000 25 000 federal', '-9.4194          taxes    -12.4938         000 38', '-9.4331            new    -12.4938     000 38 000', '-9.4862        billion    -12.4938000 38 000 earned', '-9.5115           care    -12.4938  000 40 000 50', '-9.5466         united    -12.4938        000 400', '-9.5504           rate    -12.4938    000 400 000', '-9.5529  united states    -12.4938000 400 000 military', '-9.5836        federal    -12.4938000 50 000 year', '-9.6116      americans    -12.4938        000 500', '-9.6434           said    -12.4938 000 500 severe', '-9.6522            cut    -12.4938000 500 severe vaccine', '-9.6621         budget    -12.4938         000 97', '-9.6718             10    -12.4938     000 97 000', '-9.6783          voted    -12.4938000 97 000 just', '-9.6873    health care    -12.4938    000 african', '-9.6943            pay    -12.4938000 african americans', '-9.6970           time    -12.4938000 african americans andwas', '-9.7036           debt    -12.4938000 american jobs', '-9.7360       american    -12.4938000 american jobs including', '-9.7391        average    -12.4938000 americans simply', '-9.7663        florida    -12.4938000 americans simply given', '-9.7801     government    -12.4938     000 anchor', '-9.7932            law    -12.4938000 anchor babies', '-9.8016       spending    -12.4938000 anchor babies born', '-9.8063     republican    -12.4938    000 applied', '-9.8246        highest    -12.4938000 applied equally', '-9.8427          money    -12.4938000 applied equally granted', '-9.8442         barack    -12.4938     000 babies', '-9.8617          times    -12.4938000 babies born', '-9.8748           just    -12.4938000 babies born deformed', '-9.8761         school    -12.4938000 barrels day', '-9.8818          world    -12.4938000 barrels day able', '-9.8855            day    -12.4938000 barrels oil day', '-9.9084         senate    -12.4938       000 beef']\n",
      "['2.0315        percent    -1.5708      obamacare', '1.8048      countries    -1.4197      wisconsin', '1.6195            day    -1.3027          obama', '1.6157        georgia    -1.2967            rep', '1.4357          times    -1.1417     government', '1.4045        average    -1.0632           away', '1.3988        million    -1.0549       illegals', '1.3347           debt    -1.0137           says', '1.2845         months    -0.9930   scott walker', '1.1959           half    -0.9560          group', '1.1058       american    -0.9553         obamas', '1.1058          terms    -0.9542           plan', '1.0753            cut    -0.9471        illegal', '1.0721            000    -0.9384nuclear weapons', '1.0521         cities    -0.9354          white', '1.0434          lower    -0.9232       released', '1.0430        decades    -0.9213         walker', '1.0325             60    -0.9170         muslim', '1.0281        country    -0.9116           face', '1.0233   percent time    -0.9049    seven years', '1.0137          worth    -0.8953          china', '1.0122        highest    -0.8939         gotten', '1.0055       shutdown    -0.8924           stop', '0.9976     says scott    -0.8705        cabinet', '0.9718        members    -0.8687      dont know', '0.9539      lobbyists    -0.8608           seat', '0.9473        opposed    -0.8582       benghazi', '0.9462   corporations    -0.8475          fight', '0.9258           ohio    -0.8411      president', '0.9209       georgias    -0.8410           team', '0.9064            won    -0.8359           real', '0.8997         dollar    -0.8331            tom', '0.8899       expanded    -0.8326            aid', '0.8881        elected    -0.8304           care', '0.8802           weve    -0.8291     christians', '0.8702      committee    -0.8131       deciding', '0.8625             14    -0.8121      virginias', '0.8523        workers    -0.8027      jobs lost', '0.8495          share    -0.8019    500 billion', '0.8421       spending    -0.7958   end medicare', '0.8398      accidents    -0.7952          taxed', '0.8363      statewide    -0.7938        selling', '0.8252             24    -0.7925        clinton', '0.8226         called    -0.7890       war iraq', '0.8196national average    -0.7867    raise taxes', '0.8193           does    -0.7832          price', '0.8175        torture    -0.7804  said drilling', '0.8158         nearly    -0.7785          lanes', '0.8124         lowest    -0.7756           free', '0.8116        college    -0.7749       bankrupt']\n",
      "['0.4506        percent    -0.6388          obama', '0.2917        million    -0.6211      obamacare', '0.2873          times    -0.5679         barack', '0.2794      countries    -0.4888   barack obama', '0.2788            day    -0.4531           care', '0.2700        georgia    -0.4323   scott walker', '0.2611            000    -0.4213         walker', '0.2445           debt    -0.4166      president', '0.2403       american    -0.4149           says', '0.2384        average    -0.3957            rep', '0.2244           half    -0.3769      wisconsin', '0.2188         months    -0.3693          scott', '0.2171        country    -0.3519    health care', '0.2152            cut    -0.3465       care law', '0.1916          state    -0.3455     government', '0.1828           ohio    -0.3324health care law', '0.1816         states    -0.3293 says president', '0.1798says donald trump    -0.3254           plan', '0.1777          terms    -0.3244         obamas', '0.1760         cities    -0.3204        clinton', '0.1759          lower    -0.3200       medicare', '0.1736        members    -0.3086says barack obama', '0.1729     republican    -0.3074       security', '0.1726        program    -0.3052      gov scott', '0.1721           weve    -0.2994         social', '0.1715       spending    -0.2850    says barack', '0.1706           does    -0.2827gov scott walker', '0.1698         called    -0.2783        hillary', '0.1685        workers    -0.2697social security', '0.1672        highest    -0.2591president barack', '0.1660       trillion    -0.2504           away', '0.1651         dollar    -0.2481       stimulus', '0.1650      lobbyists    -0.2435   tax increase', '0.1634           year    -0.2412          voted', '0.1614             60    -0.2377          going', '0.1568       actually    -0.2210          white', '0.1566          trump    -0.2205       increase', '0.1564        funding    -0.2170hillary clinton', '0.1550         mccain    -0.2158tax increase history', '0.1549        poverty    -0.2155says president barack', '0.1544         nearly    -0.2136       supports', '0.1542           rate    -0.2126       deciding', '0.1540            won    -0.2124       says rep', '0.1534         romney    -0.2116         muslim', '0.1534        college    -0.2100          wants', '0.1533           time    -0.2065increase history', '0.1529   percent time    -0.1976    500 billion', '0.1522      americans    -0.1975    raise taxes', '0.1504   corporations    -0.1972president barack obama', '0.1496        florida    -0.1930largest tax increase history']\n"
     ]
    }
   ],
   "source": [
    "def show_most_informative_features(model, vect, clf, text=None, n=50):\n",
    "    # Extract the vectorizer and the classifier from the pipeline\n",
    "    vectorizer = model.named_steps[vect]\n",
    "    classifier = model.named_steps[clf]\n",
    "\n",
    "     # Check to make sure that we can perform this computation\n",
    "    if not hasattr(classifier, 'coef_'):\n",
    "        raise TypeError(\n",
    "            \"Cannot compute most informative features on {}.\".format(\n",
    "                classifier.__class__.__name__\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    if text is not None:\n",
    "        # Compute the coefficients for the text\n",
    "        tvec = model.transform([text]).toarray()\n",
    "    else:\n",
    "        # Otherwise simply use the coefficients\n",
    "        tvec = classifier.coef_\n",
    "\n",
    "    # Zip the feature names with the coefs and sort\n",
    "    coefs = sorted(\n",
    "        zip(tvec[0], vectorizer.get_feature_names()),\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Get the top n and bottom n coef, name pairs\n",
    "    topn  = zip(coefs[:n], coefs[:-(n+1):-1])\n",
    "\n",
    "    # Create the output string to return\n",
    "    output = []\n",
    "\n",
    "    # If text, add the predicted value to the output.\n",
    "    if text is not None:\n",
    "        output.append(\"\\\"{}\\\"\".format(text))\n",
    "        output.append(\n",
    "            \"Classified as: {}\".format(model.predict([text]))\n",
    "        )\n",
    "        output.append(\"\")\n",
    "\n",
    "    # Create two columns with most negative and most positive features.\n",
    "    for (cp, fnp), (cn, fnn) in topn:\n",
    "        output.append(\n",
    "            \"{:0.4f}{: >15}    {:0.4f}{: >15}\".format(\n",
    "                cp, fnp, cn, fnn\n",
    "            )\n",
    "        )\n",
    "    #return \"\\n\".join(output)\n",
    "    print(output)\n",
    "\n",
    "show_most_informative_features(logR_pipeline_ngram,vect='LogR_tfidf',clf='LogR_clf')\n",
    "show_most_informative_features(nb_pipeline_ngram,vect='nb_tfidf',clf='nb_clf')\n",
    "show_most_informative_features(svm_pipeline_ngram,vect='svm_tfidf',clf='svm_clf')\n",
    "show_most_informative_features(sgd_pipeline_ngram,vect='sgd_tfidf',clf='sgd_clf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#doc_new = ['obama is running for president in 2016']\n",
    "\n",
    "var = input(\"Please enter the news text you want to verify: \")\n",
    "print(\"You entered: \" + str(var))\n",
    "\n",
    "\n",
    "#function to run for prediction\n",
    "def detecting_fake_news(var):    \n",
    "#retrieving the best model for prediction call\n",
    "    load_model = pickle.load(open('final_model.sav', 'rb'))\n",
    "    prediction = load_model.predict([var])\n",
    "    prob = load_model.predict_proba([var])\n",
    "\n",
    "    return (print(\"The given statement is \",prediction[0]),\n",
    "        print(\"The truth probability score is \",prob[0][1]))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    detecting_fake_news(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
