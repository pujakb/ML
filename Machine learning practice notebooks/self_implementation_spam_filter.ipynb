{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dictionary=['Free','Click here','visit','open attachment',\n",
    "                 'call this number','money','Out','extra','offer','available','Pension','Opportunity','Chance','Investment','Pension'];\n",
    "spam_dictionary=[w.lower() for w in spam_dictionary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1=('I wanted to let you know about money that is available for college in your State .The amount is up to $5,730* if you qualify.'\n",
    "'It takes like 2 minutes to check if you qualify.Click Here to get matched.')\n",
    "doc_2=('Free -Coupons for next movie. T he above links will take you straight to our partner\\'s site. For more information or to see other'\n",
    "'offers available, you can also visit the Groupon on the Working Advantage website.')\n",
    "doc_3=('Our records indicate your Pension is under performing to see higher growth and up to 25% cash release reply PENSION for a free review.'\n",
    "'To opt out reply STOP')\n",
    "doc_4=('Enter to win $25,000 and get a Free Hotel Night! Just click here for a $1 trial membership in NetMarket, the Internet\\'spremier '\n",
    "'discount shopping site: Fast Company EZVenture gives you FREE business articles,PLUS, you could win YOUR CHOICE of a BMW Z3 convertible, '\n",
    "'$100,000, shares of Microsoft stock, or a home office computer. Go there and get your chances to win now. A crazy-funny-cool trivia book '\n",
    "'with a $10,000 prize? PLUS chocolate, nail polish, cats, barnyard animals, and more?')\n",
    "doc_5=('Dear recipient,Avangar Technologies announces the beginning of a new unprecendented global employment campaign.Due to company\\'s '\n",
    "'exploding growth Avangar is expanding business to the European region.During last employment campaign over 1500 people worldwide took part' \n",
    "'in Avangar\\'s business and more than half of them are currently employed by the company. And now we are offering you one more opportunity to '\n",
    "'earn extra money working with Avangar Technologies. We are looking for honest, responsible, hard-working people that can dedicate 2-4 hours '\n",
    "'of their time per day and earn extra Â£300-500 weekly. All offered positions are currently part-time and give you a chance to work mainly from home.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I wanted to let you know about money that is available for college in your State .The amount is up to $5,730* if you qualify.It takes like 2 minutes to check if you qualify.Click Here to get matched.'"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chidananda.pati/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/chidananda.pati/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_doc(doc):\n",
    "    doc_word_tokens = word_tokenize(doc) \n",
    "    doc_filtered = [w.lower() for w in doc_word_tokens if not w in stop_words] \n",
    "    return doc_filtered;\n",
    "\n",
    "doc_1_tokens=filtered_doc(doc_1)\n",
    "doc_2_tokens=filtered_doc(doc_2)\n",
    "doc_3_tokens=filtered_doc(doc_3)\n",
    "doc_4_tokens=filtered_doc(doc_4)\n",
    "doc_5_tokens=filtered_doc(doc_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "def tf(term_freq):\n",
    "    if (term_freq == 0):\n",
    "        return 0;\n",
    "    else:\n",
    "        return round(1+log(1+log(term_freq,10),10),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(total_num_docs,total_num_docs_with_term):\n",
    "    return round(log((1+total_num_docs)/total_num_docs_with_term,10),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(term_freq,total_num_docs,total_num_docs_with_term):\n",
    "    return round(tf(term_freq)*idf(total_num_docs,total_num_docs_with_term),4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.301"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def term_freq(terms,doc):\n",
    "    counts=Counter(doc);\n",
    "    return [counts[term] for term in terms];  \n",
    "\n",
    "def docs_with_term(terms,docs):\n",
    "    docs_with_term_arr=np.zeros(len(terms))\n",
    "    for idx in range(len(terms)):\n",
    "        count=0;\n",
    "        term=terms[idx]\n",
    "        for doc in docs:\n",
    "            if term in doc:\n",
    "                count=count+1;\n",
    "                docs_with_term_arr[idx]=count;\n",
    "    return docs_with_term_arr;            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[]\n",
    "docs.append(doc_1_tokens)\n",
    "docs.append(doc_2_tokens)\n",
    "docs.append(doc_3_tokens)\n",
    "docs.append(doc_4_tokens)\n",
    "docs.append(doc_5_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 1., 2., 1., 2., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spam_dictionary=['Free','Click here','visit','open attachment',\n",
    "#                 'call this number','money','Out','extra','offer','available','Pension','Opportunity','Chance','Investment','Pension'];\n",
    "docs_with_term_arr=docs_with_term(spam_dictionary,docs)\n",
    "spam_dictionary_non_zero=['Free','visit','money','extra','available','Pension','Opportunity','Chance','Pension'];\n",
    "spam_dictionary_non_zero=[w.lower() for w in spam_dictionary_non_zero]\n",
    "docs_with_term_arr=docs_with_term(spam_dictionary_non_zero,docs)\n",
    "docs_with_term_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 1., 2., 1., 2., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_term_arr[[np.nonzero(docs_with_term_arr)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix=np.zeros((len(docs),np.size(spam_dictionary_non_zero)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rowIdx in range(tf_idf_matrix.shape[0]):\n",
    "    term_freq_doc=term_freq(spam_dictionary_non_zero,docs[rowIdx])\n",
    "    for colIdx in range(tf_idf_matrix.shape[1]):\n",
    "        tf_idf_matrix[rowIdx,colIdx] =tf_idf(term_freq_doc[colIdx],5,docs_with_term_arr[rowIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['free', 'visit', 'money', 'extra', 'available', 'pension', 'opportunity', 'chance', 'pension']\n",
      "[[0.     0.     0.301  0.     0.301  0.     0.     0.     0.    ]\n",
      " [0.7782 0.7782 0.     0.     0.7782 0.     0.     0.     0.    ]\n",
      " [0.4771 0.     0.     0.     0.     0.5316 0.     0.     0.5316]\n",
      " [0.8671 0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.4771 0.5316 0.     0.     0.4771 0.4771 0.    ]]\n"
     ]
    }
   ],
   "source": [
    "print(spam_dictionary_non_zero)\n",
    "print(tf_idf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
